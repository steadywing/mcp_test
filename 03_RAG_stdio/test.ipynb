{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e45b86a",
   "metadata": {},
   "source": [
    "> Warning 원인: <br>\n",
    "이 경고는 pin_memory=True 설정이 되어 있지만, macOS의 MPS(Metal Performance Shaders)는 해당 기능을 지원하지 않아서 발생합니다. CUDA 환경에서는 유효한 옵션이지만, macOS는 CUDA를 지원하지 않기 때문에 무시되는 것입니다.\n",
    "> ```\n",
    "> ⚠️ UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used. \n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43d48ed",
   "metadata": {},
   "source": [
    "# 1. PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9634ae45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88b2c83820494afe87fbedde01dc6ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c90352fc6641d581e0da0c124060e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac3bb1e4e7d34c1c9300b6cb79503981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6817d9585341fda75e4b860a887b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "FILE_PATH = \"/Users/narae/wanted/mcp_exercise/03_RAG_stdio/resources/SPRi AI Brief_Special_딥시크(DeepSeek)의 등장과 영향.pdf\"\n",
    "\n",
    "loader = DoclingLoader(file_path=FILE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b71b3",
   "metadata": {},
   "source": [
    "## 한번에 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa5edb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narae/wanted/mcp_exercise/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f19d0f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '/Users/narae/wanted/mcp_exercise/03_RAG_stdio/resources/SPRi AI Brief_Special_딥시크(DeepSeek)의 등장과 영향.pdf', 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta', 'version': '1.0.0', 'doc_items': [{'self_ref': '#/texts/2', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 154.2, 't': 570.341, 'r': 339.21, 'b': 550.006, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 19]}]}, {'self_ref': '#/texts/3', 'parent': {'$ref': '#/body'}, 'children': [], 'content_layer': 'body', 'label': 'text', 'prov': [{'page_no': 1, 'bbox': {'l': 140.52, 't': 540.312, 'r': 353.043, 'b': 517.152, 'coord_origin': 'BOTTOMLEFT'}, 'charspan': [0, 27]}]}], 'headings': ['[AI브리프 스페셜] 딥시크(DeepSeek)의 등장과 영향'], 'origin': {'mimetype': 'application/pdf', 'binary_hash': 6092602432486382245, 'filename': 'SPRi AI Brief_Special_딥시크(DeepSeek)의 등장과 영향.pdf'}}}, page_content='[AI브리프 스페셜] 딥시크(DeepSeek)의 등장과 영향\\n-  Brief  Special -\\n중국과 일본의 생성AI 동향 호 2025년  2월')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7453d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': '/Users/narae/wanted/mcp_exercise/03_RAG_stdio/resources/SPRi AI Brief_Special_딥시크(DeepSeek)의 등장과 영향.pdf',\n",
       " 'dl_meta': {'schema_name': 'docling_core.transforms.chunker.DocMeta',\n",
       "  'version': '1.0.0',\n",
       "  'doc_items': [{'self_ref': '#/texts/2',\n",
       "    'parent': {'$ref': '#/body'},\n",
       "    'children': [],\n",
       "    'content_layer': 'body',\n",
       "    'label': 'text',\n",
       "    'prov': [{'page_no': 1,\n",
       "      'bbox': {'l': 154.2,\n",
       "       't': 570.341,\n",
       "       'r': 339.21,\n",
       "       'b': 550.006,\n",
       "       'coord_origin': 'BOTTOMLEFT'},\n",
       "      'charspan': [0, 19]}]},\n",
       "   {'self_ref': '#/texts/3',\n",
       "    'parent': {'$ref': '#/body'},\n",
       "    'children': [],\n",
       "    'content_layer': 'body',\n",
       "    'label': 'text',\n",
       "    'prov': [{'page_no': 1,\n",
       "      'bbox': {'l': 140.52,\n",
       "       't': 540.312,\n",
       "       'r': 353.043,\n",
       "       'b': 517.152,\n",
       "       'coord_origin': 'BOTTOMLEFT'},\n",
       "      'charspan': [0, 27]}]}],\n",
       "  'headings': ['[AI브리프 스페셜] 딥시크(DeepSeek)의 등장과 영향'],\n",
       "  'origin': {'mimetype': 'application/pdf',\n",
       "   'binary_hash': 6092602432486382245,\n",
       "   'filename': 'SPRi AI Brief_Special_딥시크(DeepSeek)의 등장과 영향.pdf'}}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2400fcc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'dl_meta'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9f7385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AI브리프 스페셜] 딥시크(DeepSeek)의 등장과 영향\n",
      "-  Brief  Special -\n",
      "중국과 일본의 생성AI 동향 호 2025년  2월\n",
      "==================================================\n",
      "딥시크(DeepSeek)의 등장과 영향\n",
      "최근 중국의 스타트업인 딥시크는 DeepSeek-R1 모델을 출시하며 크게 주목받고 있다. 딥시크가 개발한 AI  모델은  중국  내에서는  AI  독립성을  강화하는  기술로  평가되고, 벤치마킹  결과  특정  작업에서  오픈AI의  GPT-4와  경쟁할  수  있는  성능을  보였다고 보고하지만, 국제적으로는 정책 검열, 보안, 개인정보보호 관련 우려가 제기된다. 미국, 유럽 등 여러 국가에서 데이터 보안 및 개인정보 보호 문제로 딥시크의 사용을 제한하는 조치가 확대되고 있다. 이러한 논란 속에서도 딥시크는 AI 시장의 새로운 경쟁 구도를 형성하고 있으며, 향후 글로벌 AI 산업의 변화에 중대한 영향을 미칠 것으로 전망된다.\n",
      "==================================================\n",
      "£ 2025년  1월  20일,  중국의  스타트업인  딥시크(창업자:  량원평)가  전세계  AI  산업계에  상당한 파급력을 갖는 DeepSeek-R1 모델(이하 R1 모델)을 출시 1)2)\n",
      "∙ 딥시크의 추론형 AI 모델 'R1'과 'R1-Zero'*는 AI 연구 커뮤니티와 업계 관계자들 사이에서 상당한 화제로 부상 3)\n",
      "* R1-Zero는  강화학습만으로  학습된  모델로  지도학습  기반  파인튜닝(Supervised  Fine-Tuning,  SFT)  없이  스스로  문제 해결하는  모델이며,  반면에  R1은  소량의  콜드스타트(Cold-start)  데이터와  다단계  학습  과정을  통해  더욱  향상된  성능과 가독성을 제공하는 모델\n",
      "==================================================\n",
      "£ 2025년  1월  20일,  중국의  스타트업인  딥시크(창업자:  량원평)가  전세계  AI  산업계에  상당한 파급력을 갖는 DeepSeek-R1 모델(이하 R1 모델)을 출시 1)2)\n",
      "∙ 딥시크는 R1 모델 발표와 함께 AI 산업에서 핵심 플레이어 중 하나로 빠르게 자리 잡아가고 있으며 가성비 높은 AI 모델로서의 입지를 구축해가는 추세\n",
      "==================================================\n",
      "£ 오픈AI 및 구글은  기반모델을  개발하여  폐쇄적인  형태로  운영하는  반면,  딥시크는 오픈소스 기반으로 R1 모델 개발 4)\n",
      "∙ 딥시크는 오픈소스 기반으로 지식 증류와 다단계 강화학습과 같은 비용 절감 기술을 도입하여 AI 모델의 효율성을 향상 5)\n",
      "∙ R1 모델은 AI 학습의 효율성을 극대화하기 위해 전문가 혼합(MoE, Mixture-of-Experts) 기술을 활용\n",
      "∙ 딥시크는 벤치마킹 평가 결과를 통해 R1 모델이 GPT-4 모델과 경쟁할 만한 성능을 기록했다고 주장\n",
      "1) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "2) Deloitte, 딥시크가 촉발한 새로운 AI 경쟁시대, 2025.2.\n",
      "3) Reuters, Chinese chip makers, cloud providers rush to embrace homegrown DeepSeek, 2025.2.5.\n",
      "==================================================\n",
      "£ 오픈AI 및 구글은  기반모델을  개발하여  폐쇄적인  형태로  운영하는  반면,  딥시크는 오픈소스 기반으로 R1 모델 개발 4)\n",
      "4) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "5) DeepSeek-AI, DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model, 2024.5.7.\n",
      "1\n",
      "==================================================\n",
      "£ 중국  정부가  AI  산업  진흥과  동시에  관련  보안  규제를  강화하는  환경에서  중국의 스타트업인  딥시크는  오픈AI,  구글,  메타  등  선도적인  AI  기업에  대한  의존도를  낮출  수 있는 AI 기술을 공개하였다고 평가 6)7)\n",
      "∙ 중국은 공격적으로 디지털 주권을 추구하며, AI 개발이 경제 성장, 사회적 안정, 전략적·군사적 이점을 포함한 국가적 우선순위와 일치하도록 엄격히 감독하고, 데이터 현지화, 알고리즘 등록 및 엄격한 콘텐츠 통제를 요구하는 정책을 시행 8)\n",
      "∙ R1 모델은 AI 기반모델 분야에서 중국이 미국 및 유럽과의 AI 기술 격차를 좁히는 데 핵심적인 역할을 할 것으로 평가\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "∙ 신화통신과 차이나데일리는 딥시크가 중국의 AI 독립성을 강화하는 데 기여하고 있다고 강조\n",
      "*  중국  인공지능(AI)  애플리케이션인 딥시크가 고품질 콘텐츠와 접근성으로 인해 러시아 사용자들에게 인기를 얻고 있음(신화통신 9) )\n",
      "*  중국  AI  기업  딥시크는  최근  획기적인  AI  모델을  선보이며  주요  미국  기술  회사로부터  긍정적인  반응을 얻음(차이나데일리) 10)\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "∙ 반면, 일부 서방 언론은 딥시크의 기술적 발전을 인정하면서도, 투명성, 데이터 출처, 중국의 AI 규제가 초래할 수 있는 잠재적 제한에 대한 우려를 제기\n",
      "* AI  회사인  딥시크는  모델이  학습되는  방식을  개선하여  방대한  컴퓨팅  중심  인프라에  의존하는  대신,  강화학습과  전문가 혼합(MoE)  아키텍처를 활용하여 컴퓨팅 수요를 줄이는 동시에 성능을 개선(IDC) 11)\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "*  '딥시크  팀은  오픈소스,  고성능  모델을  출시함으로써  중요한  이정표를  달성'(에든버러대  Luo  Mai  박사),  '미국  외에서  가장 경쟁력 있는 모델로 보임'(리즈 대학의 Anthony G Cohn 교수) 12)  등의 전문가 평가 존재\n",
      "*  프랑스의  개인정보  보호  기관인  CNIL은  딥시크의  AI  시스템이  개인정보에 미치는 영향을  조사할 계획 13)\n",
      "6) bruegel, The geopolitics of artificial intelligence after DeepSeek, 2025.2.4.\n",
      "7) DLA PIPER, China releases AI safety governance framework, 2024.09.12.\n",
      "8) Geop litical Monitor, The Global AI Race: The Geopolitics of DeepSeek, 2025. 2.12.\n",
      "9) Xinhuanet, DeepSeek gains popularity in Russia for high-quality content, accessibility: media, 2025.2.12.\n",
      "10) China Daily, DeepSeek's AI breakthrough widely recognized by US tech industry, 2025.2.12.\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "11) IDC, DeepSeek's AI Innovation: A Shift in AI Model Efficiency and Cost Structure, 2025.1.31\n",
      "12) Science Media Centre, expert reaction to new AI Chatbot DeepSeek, 2025.1.28.\n",
      "13) Reuters, French privacy watchdog to quiz DeepSeek on AI, data protection, 2025.1.31.\n",
      "==================================================\n",
      "£ 딥시크의 V3 모델은 전문가 혼합(Mixture-of-Experts, MoE) 아키텍처 기반한 언어모델로, 딥시크 R1 모델 개발을 위한 기초 모델(Basic Model)로 사용\n",
      "∙ V3  모델은  총  6,710억  개(671B)의  파라미터를  보유하고  있지만,  각  토큰을  처리할  때  활성화되는 파라미터는 370억 개(37B)만 사용하도록 설계\n",
      "∙ 총 14.8조 개의 고품질 데이터를 사용하여 사전학습하고, 지도학습 미세조정(Supervised Fine-Tuning)과 강화학습(Reinforcement Learning, RL)을 통해 모델의 성능을 극대화\n",
      "∙ 총 2.788M(278만 8천) H800 GPU 시간을 소요하여 학습을 완료(최신 AI 모델 중에서도 비교적 저렴한 비용으로 학습)\n",
      "==================================================\n",
      "£ 딥시크의 V3 모델은 전문가 혼합(Mixture-of-Experts, MoE) 아키텍처 기반한 언어모델로, 딥시크 R1 모델 개발을 위한 기초 모델(Basic Model)로 사용\n",
      "∙ V3 모델은 다른 오픈소스 모델보다 우수한 성능을 보이고, 폐쇄형 모델(예: OpenAI GPT-4 등)과 경쟁할 만한 성능을 기록\n",
      "==================================================\n",
      "<V3  모델의  주요  기술>\n",
      "MoE (Mixture-of-Experts), 주요내용 = ∙ V3모델은MoE를적용해특정작업에적합한신경망모듈만활성화함으로써연산효율성과응답품질을최적화 ∙ 특히, 기초모델을수학,코딩등특정작업에최적화된여러개의소규모전문가모델로나누어 학습부담을줄이는방식을적용 ∙ 딥시크가MoE 기술을적용하였다는측면에서는DeepSeek-V3의 아키텍처가완전히새로운 혁신이라기보다는기존연구의발전형태로볼수있다는평가도존재. MLA(Multi-head Latent Attention), 주요내용 = ∙ 딥시크의V3모델은기존MHA(Multi-head-Attention) 대비개선된MLA기술을적용하여더욱더 효율적으로정보를처리하고,계산속도를높이면서도메모리사용량을줄여추론을빠르게수행. 보조손실(auxiliary-loss) 없는로드밸런싱, 주요내용 = ∙ 기초적인 구조를 갖는 MoE 모델에서는 일반적으로 전문가 모델 간의 부하를 균등하게 분배 하기위해추가적인손실(loss)을 설정 ∙ 보조손실없는로드밸런싱을갖는V3는추가손실없이도효과적으로부하를분산하도록설계. 다중토큰예측(Multi-token Prediction), 주요내용 = ∙ 일반적인언어모델은한번에하나의토큰을예측하지만,V3모델은한번에여러개의토큰을 예측하는방식을적용하여성능을향상\n",
      "14) DeepSeek-AI, DeepSeek-V3 Technical Report, 2024.12.27.\n",
      "15) The Alan Turing Institute, Brief analysis of DeepSeek R1 and its implications for Generative AI, 2025.2.7.\n",
      "3\n",
      "==================================================\n",
      "<V3  모델  아키텍쳐>\n",
      "- *  출처:  DeepSeek-A,  DeepSeek-V3  Technical  ReportI 16)\n",
      "==================================================\n",
      "2)  DeepSeek-R1  -  추론(Reasoning) 17)18)\n",
      "£ (R1-Zero  모델  개발)  딥시크  연구팀은  순수  강화학습(Reinforcement  Learning,  RL)만을 활용하여  추론  능력을  향상하고,  자체적으로  진화하는  모델을  목표로  한  프로젝트에서 DeepSeek-R1-Zero(이하 R1-Zero) 모델을 개발\n",
      "∙ 딥시크의 연구팀은 개발 목표가 순수 RL 프로세스를 통해 자기 진화에 초점을 맞추어, 지도학습 데이터를 사용하지 않으면서 LLM이 추론 능력을 개발할 수 있는 잠재력을 탐구하는 것이었다고 설명\n",
      "∙ 특히,  모델의  추론  능력  향상을  위해  V3-base  모델(DeepSeek-V3-Base,  6,710억  파라미터)을 기반으로 하여 GRPO(Group Relative Policy Optimization) 기법*을 강화학습 프레임워크로 적용하여 R1-Zero 모델을 개발\n",
      "==================================================\n",
      "2)  DeepSeek-R1  -  추론(Reasoning) 17)18)\n",
      "16) DeepSeek-AI, DeepSeek-V3 Technical Report, 2024.12.27.\n",
      "17) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "18) The Alan Turing Institute, Brief analysis of DeepSeek R1 and its implications for Generative AI, 2025.2.7\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "*  GRPO(Generalized  Relative  Policy  Optimization):  대규모  언어  모델(LLM)에서  추론  능력을  강화하도록  설계된  강화학습 알고리즘으로,  비용이  많이  소요되며  평가자에  크게  의존하는  기존  강화학습  방법과  달리  GRPO는  응답  그룹을  서로  비교 평가하여 모델을 최적화\n",
      "∙ 일반적인 강화학습에서는 보통 정책 모델(Policy Model)과 비평 모델(Critic Model)을 함께 사용하여 학습을 진행하며, 비평 모델은 정책 모델과 같은 크기로 만들어야 하는 경우가 많아, 학습 비용이 매우 비싸지는 단점 존재\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "∙ V3 모델은 강화학습 비용을 절감하기 위해 GRPO 기법을 사용하여 별도의 비평 모델을 두지 않고, 대신 여러 개의 정답 후보(출력값)를 그룹으로 묶고, 여러 개의 답변을 비교하면서 상대적으로 더 좋은 답변을 학습\n",
      "==================================================\n",
      "<PPO와  GRPO  비교>\n",
      "*  출처:  DeepSeek-AI,  Tsinghua  University,  Peking  University 19)\n",
      "∙ R1-Zero 모델은 추론 및 수학적 문제 해결 성능이 향상*\n",
      "*  R1-Zero  모델  성능  개선:  ▲AIME  2024  벤치마크  성능  15.6%  →  71.0%▲강화학습의  다수결  투표(Majority  Voting)  기법 추가 후 86.7% 성능 도달(OpenAI o1-0912와 유사한 수준)\n",
      "∙ 그러나, R1-Zero 모델은 추론 및 수학적 문제 해결 성능의 우수성은 높았지만. 가독성(Readability)이 낮고 언어 혼합(Language Mixing) 등의 문제점 존재\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "∙ 딥시크 연구팀은 V3-Base 모델 미세조정을 위해 수천 개의 콜드스타트 데이터(Cold-start Data)*를 수집\n",
      "*  콜드스타트  데이터는  머신러닝  모델의  학습을  초기화하거나  \"킥스타트\"하는  데  사용되는  소량의  고품질  지도학습  데이터를 말하며, 특히 모델을 처음부터 학습하거나 새로운 작업으로 전환하는 시나리오에서 사용\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "∙ 이어 V3-Base 모델을 콜드스타트 데이터로 미세 조정하고, R1-Zero와 유사한 방식으로 대형 R1 모델에 강화학습 적용*\n",
      "*  특히  코딩,  수학,  과학,  논리적  사고(Logical  Reasoning)와  같은  명확한  정답이  있는  문제  해결  능력을  강화하는  데  집중\n",
      "∙ 강화학습  과정에서  연쇄적  사고(Chain  of  Thought,  CoT)  과정에서  여러  언어가  혼합되는  언어 혼합(Language Mixing 등의 문제점을 발견하여 보상 체계를 최적화하는 방식으로 해결*\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "*  강화학습  과정에서  여러  언어가  포함된  강화학습  프롬프트를  학습할  때  여러  언어가  혼합되는  문제가  발생하여  이러한  문제를 해결하기 위해 연쇄적 사고(CoT)에서 목표 언어의 비율을 계산하여 보상을 부여하는 방식을 적용\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "∙ 강화학습 과정이 일정 수준의 성능(수렴 단계)에 도달하면, 기존 모델의 성능을 보다 더 향상하기 위해 새로운 학습 데이터로 모델을 미세 조정하며, 이러한 과정은 다음과 같은 과정을 통해 수행\n",
      "① 거부 샘플링(Rejection Sampling): 강화학습을 통해 다양한 답변 중 품질이 높은 데이터만 선별\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "② 지도학습  미세조정(SFT)  데이터  추가:  ①에서  선별된  데이터와  기존  V3  모델에서  수집한  SFT 데이터(예: 글쓰기, 사실 기반 질의응답, 자기 인식 관련 데이터)와 결합\n",
      "③ 모델 재훈련(retrain): 새로운 데이터로 V3-Base 모델을 재학습시켜 더욱 정교한 AI 모델을 완성\n",
      "==================================================\n",
      "<거부 샘플링 및 지도학습 미세조정으로 수집된 추론 및 비 추론 학습 데이터>\n",
      "추론 데이터, 주요내용 = ∙ 추론프롬프트를수집,강화학습과정에서생성된체크포인트모델출력중품질높은데이터를선별해학습데이터로활용 ∙ 이전 단계에서 규칙 기반 보상(rule-based rewards)을 사용해 평가할 수 있는 데이터만 포함했지만, 이번 단계에서는추가데이터를포함하여데이터셋을확장 - 일부 데이터는 생성형 보상 모델(generative reward model)을 활용하여 평가되며, 이를 위해 정답 (Ground Truth)과 모델의예측결과를V3모델에입력하여평가 ∙ 모델이 생성한 답변이 혼란스럽거나 가독성이 낮은 경우를 방지하기 위해, 언어가 섞인 문장, 너무 긴 문단, 코드블록이포함된응답을필터링 ∙ 각프롬프트에대해여러개의응답을생성한후,정확한응답만남김 ∙ 최종적으로, 총60만개(600k)의 추론관련학습데이터를수집. 비추론 데이터, 주요내용 = ∙ 추론과\n",
      "==================================================\n",
      "<거부 샘플링 및 지도학습 미세조정으로 수집된 추론 및 비 추론 학습 데이터>\n",
      "관련이 없는 글쓰기, 사실 기반 질의응답(factual QA), 자기 인식(self-cognition), 번역 (translation) 등의 작업에서는 V3 모델의 기존 학습 데이터 파이프라인을 활용하고, V3의 모델의 지도학습 미세조정데이터셋을일부재사용 ∙ 특정비추론작업에서는V3모델을활용해먼저CoT(연쇄적사고)를생성한후답변을생성 ∙ 최종적으로, 총20만개(200k)의 비추론학습데이터를수집\n",
      "*  출처:  DeepSeek-AI\n",
      "==================================================\n",
      "<거부 샘플링 및 지도학습 미세조정으로 수집된 추론 및 비 추론 학습 데이터>\n",
      "- ∙ 모델에 대한 미세조정을 완료한 이후, 모델이 다양한 상황에서 더 나은 응답을 할 수 있도록 모든 종류의 프롬프트(질문이나 입력)를 반영하며 추가적인 강화학습을 수행하여 최종 R1 모델을 완성\n",
      "==================================================\n",
      "£ (R1  모델  연구의  중요한  발견  1)  강화학습  과정에서  R1-Zero  모델이  'aha  모멘트(아하 순간)'를 통해 문제 해결 방법을 탐색\n",
      "∙ 강화학습 프로세스는 R1-Zero 모델이 추론 과제를 해결하기 위해 더 많은 토큰(즉, 더 긴 사고 과정)을 생성하도록 하며, 테스트 시간 계산이 증가함에 따라 반성과 대안적 접근 방식에 대한 탐색과 같은 행동이 자연스럽게 발생(이러한 순간을 '아하 순간'이라 칭함)\n",
      "*  '아하  순간'이라는  용어는 중간  모델이 인간형 톤(tone)을  사용하여 재고하는 법을 배우는 순간에 기인\n",
      "==================================================\n",
      "£ (R1  모델  연구의  중요한  발견  1)  강화학습  과정에서  R1-Zero  모델이  'aha  모멘트(아하 순간)'를 통해 문제 해결 방법을 탐색\n",
      "∙ 딥시크 연구팀은 '아하 순간'은 모델이 자체적인 반성(self-reflection)을 통해 점진적으로 더 나은 답변을 생성하는 능력을 갖추고 있는지, 혹은 GPT 초기 모델이 글을 생성하는 방식과 유사하게 학습되는지를 연구할 필요가 있는 중요한 발견이라 설명\n",
      "==================================================\n",
      "£ (R1  모델  연구의  중요한  발견  2)  강화학습 과정에서 언어 일관성을 높이면 모델 성능이 감소\n",
      "∙ R1 모델을 연구하는 과정에서, 강화학습 프롬프트를 추가하여 언어 일관성을 높이려고 했을 때, 모델의 성능이 오히려 감소하는 현상 확인\n",
      "∙ 딥시크의 연구에서 언어의 가독성과 사용성을 강화하려는 과정에서 벤치마크 성능과의 균형을 유지해야 하는 문제가 발생하였으며, 최종적으로, AIME 2024 벤치마크에서 79.8%의 성능을 기록\n",
      "==================================================\n",
      "£ 딥시크 연구팀은 대형 모델(R1 모델)에서 작은 모델로 '지식 증류(Distillation)' 진행\n",
      "∙ 딥시크 연구팀은 R1 모델이 학습한 추론 패턴(논리적 사고 방식)을 더 작은 AI 모델에 압축하여 전이(지식 증류)하는 실험을 진행\n",
      "∙ 실험 결과, R1 모델에서 직접 지식 증류를 적용한 모델이 같은 모델에 강화학습을 적용한 것보다 더 좋은 성능을 보였음을 확인\n",
      "∙ 연구팀은 증류된 Qwen 모델에서 증류한 14B 모델이 기존의 최신 오픈소스 모델 QwQ-32B-Preview보다 훨씬 뛰어난 성능을 보였으며, Qwen 및 Llama로부터 각각 증류한 32B 모델 및 70B 모델은 추론 성능 부문에서 새로운 기록을 세웠다고 설명\n",
      "==================================================\n",
      "£ 딥시크 연구팀은 대형 모델(R1 모델)에서 작은 모델로 '지식 증류(Distillation)' 진행\n",
      "* R1-Distill-Qwen-32B  및  R1-Distill-Llama-70B는  코딩  및  수학적  추론과  관련된  작업에서  OpenAI의  o1-mini보다 우수한 성능을 보임\n",
      "==================================================\n",
      "<DeepSeek-R1  증류  모델과  타  모델과의 추론  관련  벤치마크 비교>\n",
      ",  = . , Cons264 = 26.7. , Pass21 = 78.3. ,  = 650. ,  = 38.4. ,  = 717. OpenAl-ol-mini,  = 636. OpenAl-ol-mini, Cons264 = . OpenAl-ol-mini, Pass21 = . OpenAl-ol-mini,  = . OpenAl-ol-mini,  = 53,0. OpenAl-ol-mini,  = 1820. QwQ-32B-Prview,  = . QwQ-32B-Prview, Cons264 = 6u.. QwQ-32B-Prview, Pass21 = . QwQ-32B-Prview,  = 54,5. QwQ-32B-Prview,  = 410. QwQ-32B-Prview,  = 1316. DeepSeek-RI-Distill-Qwen-LSB,  = . DeepSeek-RI-Distill-Qwen-LSB, Cons264 = . DeepSeek-RI-Distill-Qwen-LSB, Pass21 = 83,4. DeepSeek-RI-Distill-Qwen-LSB,  = 338. DeepSeek-RI-Distill-Qwen-LSB,  = 16.4. DeepSeek-RI-Distill-Qwen-LSB,  = 954. DeepSeek-RI-Dislill-Qwen-7B,  = 555. DeepSeek-RI-Dislill-Qwen-7B, Cons264 = 813. DeepSeek-RI-Dislill-Qwen-7B, Pass21 = 928. DeepSeek-RI-Dislill-Qwen-7B,  = 49.1. DeepSeek-RI-Dislill-Qwen-7B,  = . DeepSeek-RI-Dislill-Qwen-7B,  = . DeepSeek-RI-Distill-Qwen-I4B,\n",
      "==================================================\n",
      "<DeepSeek-R1  증류  모델과  타  모델과의 추론  관련  벤치마크 비교>\n",
      "= 647. DeepSeek-RI-Distill-Qwen-I4B, Cons264 = . DeepSeek-RI-Distill-Qwen-I4B, Pass21 = . DeepSeek-RI-Distill-Qwen-I4B,  = . DeepSeek-RI-Distill-Qwen-I4B,  = 53.1. DeepSeek-RI-Distill-Qwen-I4B,  = . DeepSeek-RI-Distill-Qwen-32B,  = 726. DeepSeek-RI-Distill-Qwen-32B, Cons264 = 833. DeepSeek-RI-Distill-Qwen-32B, Pass21 = . DeepSeek-RI-Distill-Qwen-32B,  = 621. DeepSeek-RI-Distill-Qwen-32B,  = 57.2. DeepSeek-RI-Distill-Qwen-32B,  = 169]. DeepSeek-RI-Distill-Llama-BB,  = . DeepSeek-RI-Distill-Llama-BB, Cons264 = . DeepSeek-RI-Distill-Llama-BB, Pass21 = 64.1. DeepSeek-RI-Distill-Llama-BB,  = 490. DeepSeek-RI-Distill-Llama-BB,  = 39.6. DeepSeek-RI-Distill-Llama-BB,  = 1205. ,  = . , Cons264 = 86.7. , Pass21 = 94.5. ,  = 65.2. ,  = 57.5. ,  = 1633\n",
      "*  출처:  DeekSeek-AI\n",
      "==================================================\n",
      "<지식 증류 개념도 예시>\n",
      "- **  딥시크가  이용한 지식증류 방법은 대규모 모델에서 작은 모델로 지식을 압축하여 성능 저하 없이 효율성을 극대화하는 기술\n",
      "==================================================\n",
      "£ DeepSeek  팀은  R1  모델이  가진  강력한  추론  능력을  더  작은  AI  모델에도  적용하기 위해,  Qwen과 Llama와 같은  오픈소스 모델을 활용하고, 증류 버전도 오픈소스로 공개\n",
      "∙ R1 모델이 학습한 80만 개(800k)의 고품질 데이터 샘플을 사용해 Qwen과 Llama 모델들에 대해 미세 조정을 수행\n",
      "∙ 딥시크 연구팀은 Qwen과 Llama 모델 시리즈의 증류 버전을 오픈소스로 공개\n",
      "20) neptune.ai, Knowledge Distillation: Principles, Algorithms, Applications, 2023.09.29.\n",
      "==================================================\n",
      "£ (연구  문제)  딥시크  연구팀은  R1-Zero  모델의  성공적인  결과를  바탕으로,  다음의  두  가지 문제를 해결하는 방안 연구\n",
      "∙ AI의  추론  능력을  더  높이고  학습  속도를  더  빠르게  하려고  고품질  데이터  일부를  초기  학습 데이터(cold-start data)로 추가하는 방법\n",
      "∙ 사용자 친화적인 AI 모델을 만들기 위해 AI가 명확하고 일관된 CoT(Chain of Thought, 연쇄적 사고)를 생성하면서도, 다양한 문제를 잘 해결할 수 있도록 학습하는 방법\n",
      "==================================================\n",
      "£ (해결  방안)  딥시크  연구팀은  연구  문제에  관해  R1  모델을  학습하기  위해  4단계로  구성된 강화학습 단계(파이프라인)을 설계\n",
      "- ∙ 1단계: 콜드스타트(Cold Start) → 2단계: 추론 지향 강화학습(Reasoning-oriented Reinforcement Learning)  →  3단계:  거부  샘플링  및  지도학습  미세조정(Rejection  Sampling  and  Supervised Fine-Tuning) → 4단계: 모든 시나리오를 위한 강화학습(Reinforcement Learning for all Scenarios)\n",
      "==================================================\n",
      "£ (콜드스타트  방법)  강화학습을  처음  시작할  때,  모델이  불안정한  상태에서  학습하는  문제를 방지하기 위해 R1  모델에서는  초기  학습  단계에서  소량의  고품질  콜드스타트  데이터(Cold Start  Data)를  먼저  학습하도록  설계\n",
      "∙ 초기 데이터를 수집하기 위해 연구팀은 ▲모델에 장문의 CoT 예제 제공, ▲세부적인 답변을 생성하도록 요청,  ▲가독성인  좋은  R1-Zero  모델의  출력  데이터를  활용,  ▲모델이  생성한  응답을  사람이  직접 수정하여 품질을 높임\n",
      "∙ 이와 같은 방식으로 수집한 수천 개의 콜드스타트 데이터를 활용해 V3-Base 모델을 먼저 미세 조정한 후 강화학습을 진행\n",
      "==================================================\n",
      "£ (콜드스타트 활용의 장점) 가독성(Readability) 및 성능(Potential)  항상\n",
      "∙ R1-Zero 모델은 여러 언어가 섞여 있고 가독성이 낮았으나, R1 모델은 응답 마지막에 요약을 추가하여 사용자 친화적인 출력 형식 제공\n",
      "∙ 사람이 직접 설계한 콜드스타트 데이터를 학습한 모델이 향상된 성능을 기록\n",
      "==================================================\n",
      "£ R1  모델은 특정 응용 분야에서 강점을 보이며, 현재 가장 발전된 AI 모델들과 경쟁 가능성 보유\n",
      "∙ 딥시크는 벤치마크 평가에서 R1 모델이 오픈AI의 o1 모델과 성능이 동등하거나 높으며, 비용은 o1 모델 대비 저렴하고, R1 모델의 기반이 된 V3 모델 학습 시 엔비디아 H100보다 성능이 절반 수준인 H800 2천 개를 사용하고, 학습 비용이 약 560만 달러에 불과했다고 주장 21)\n",
      "*  수학  관련  AIME  2024와  MATH-500  벤치마크에서  R1  모델은  각각  79.8%와  97.3%의  정확도로  o1  모델의  79.2%과 96.4%를 능가했으며, 기타 벤치마크에서도 o1 모델과 근소한 차이를 기록\n",
      "==================================================\n",
      "£ R1  모델은 특정 응용 분야에서 강점을 보이며, 현재 가장 발전된 AI 모델들과 경쟁 가능성 보유\n",
      "∙ 한편, 미국 기술 산업계 일부는 딥시크가 주장한 560만 달러는 전체 개발비의 일부일 뿐이며 H800 외에 고사양 GPU를 혼합하여 학습했을 수도 있다고 추측도 있음 22)\n",
      "==================================================\n",
      "<딥시크 R1 모델의 벤치마크 평가 결과>\n",
      "(좌측부터) 1)  AIME  2024:  미국수학협회(MAA)가  주관하는  수학  올림피아드 예선  문제\n",
      "2)  Codeforces:  전  세계  개발자들을  대상으로  하는  프로그래밍 대회  플랫폼\n",
      "3)  GPQA  Diamond:  AI  모델의  고급  추론  능력을  평가하기  위한  벤치마크\n",
      "4)  MATH-500:  수학적  추론과  문제  해결  능력을  평가\n",
      "5)  MMLU(Massive  Multitask  Language  Understanding):  다양한  학문  분야에서  AI의  작업  능력을  평가하는  벤치마크\n",
      "6)  SWE  Bench  Verified:  오픈AI에서  개발한  소프트웨어  엔지니어링  성능  평가  벤치마크\n",
      "*  출처:  deepseek;  medium.com 23)\n",
      "21) Forbes, Why DeepSeek's New AI Model Should Prompt Reality Checks For Companies, 2025. 1.29.\n",
      "22) Bain & Company, DeepSeek: A Game Changer in AI Efficiency?, 2025.2.5.\n",
      "23) Medium, Multi-head Latent Attention (MLA): Secret behind the success of DeepSeek Large Language Models, 2025.1.31.\n",
      "==================================================\n",
      "<딥시크 R1 모델의 벤치마크 평가 결과>\n",
      "- ∙ 한편,  글로벌  컨설팅사인  베인(Bain&Company)은  MMLU에  따른  LLM  비용의  추세를  분석하고, 딥시크의 이러한 비용 절감 결과는 AI 효율성의 추세와 일치하기에 그리 놀랍지 않으며, 더욱 놀라운 점은 중국 스타트업의 오픈소스 모델이 선도적인 독점 모델과의 격차를 상당히 좁히는 데 성공한 것이라고 평가\n",
      "==================================================\n",
      "<MMLU에서 백만 토큰당 가장 저렴한 LLM 비용(미국 달러, 로그 스케일)>\n",
      "- *  출처:  Bain&Company 24)\n",
      "==================================================\n",
      "2)  기술적  강점과  한계\n",
      "£ (강점)  딥시크는  중국어  자연어  처리에서  강점을  보이며,  컴퓨팅  인프라가  제한된  기업에도 적합하고, 유연한 오픈소스 전략으로 중국 AI 생태계 내에서 널리 채택\n",
      "∙ 딥시크는 자연어 처리 작업에서 우수한 성능을 보이며, 특히 중국어 기반 작업에서 두각을 나타냄 25)\n",
      "∙ 상대적으로 낮은 하드웨어 요구사항으로 컴퓨팅 인프라가 제한적인 기업에 적합 26)\n",
      "∙ 딥시크는 유연한 오픈소스 전략으로 중국 AI 생태계 내에서 광범위한 도입 진행 중\n",
      "==================================================\n",
      "2)  기술적  강점과  한계\n",
      "* BYD를  포함한  자동차  제조업체  8곳,  최소  9개의  금융증권  회사,  국유  통신  사업자  3곳이  딥시크와의  통합을  추진하고, 클라우드 컴퓨팅 사업자 알리바바, 화웨이, 텐센트, 바이두는 고객이 딥시크의 최신 모델을 이용하는 방법을 제공\n",
      "24) Bain & Company, DeepSeek: A Game Changer in AI Efficiency?, 2025.2.5.\n",
      "25) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "26)  Financial times, Transcript: Tech in 2025 - China's AI 'Sputnik moment', 2025.1.30.\n",
      "==================================================\n",
      "£ (한계) 딥시크는  텍스트  및  수치  데이터  처리에  강점을  갖지만,  멀티모달  기능이 제한적이며, 중국의 규제로 인해 정치적으로 민감한 주제에 대한 응답을 제한 27)28)\n",
      "∙ 딥시크는 주로 텍스트 및 수치 데이터 처리에 중점을 두어 멀티모달 기능이 제한적인 반면, 구글 Gemini는 텍스트, 이미지, 오디오, 비디오 입력을 처리할 수 있는 멀티모달 기능을 갖추고 있음\n",
      "∙ 딥시크는 중국의 규제 환경에서 운영되어 정치적으로 민감한 주제에 대한 응답이 제한적이므로 표현의 자유를 중시하는 국가에서는 딥시크의 도입에 대해 부정적일 수 있음\n",
      "==================================================\n",
      "£ 딥시크는  연구논문에서  MoE,  MLA 등의 기법을  활용하여  연산  자원  사용을 최적화하여 오픈AI의 GPT-4 등의 AI 모델 보다 학습비용이 낮다고 주장 29)\n",
      "∙ 그러나 일부에서는  딥시크가 비용 절감을 달성한 것으로 평가하면서도 인프라 및 인력 비용까지 고려했을 때 실제로는 보다 많이 비용이 들었을 수 있다고 추측\n",
      "*  독립적인  연구  기업인  SemiAnalysis는  딥시크의  600만  달러라는  추산은  주로  GPU  사전학습  비용을  고려하였으며,  회사에서 발생하는 연구 개발, 인프라 및 기타 필수 비용에 대한 상당한 투자는 무시되었다고 주장 30)\n",
      "==================================================\n",
      "£ 딥시크는 중국의 규제 환경 속에서 운영되어 개인정보 처리 방식에 대한 의문을 유발 31)\n",
      "∙ 중국의 사이버 보안법에 따르면, AI 기업들은 데이터를 국내에서 저장 및 처리해야 하며, 필요 시 정부 기관에 제공해야 하는 의무를 보유\n",
      "*  딥시크  약관에 수집된 데이터는 중국 내 서버에 저장되며 중국 정부의 요청 시 제공될 수 있도록 규정\n",
      "∙ 딥시크는 일반적인 생성AI와 다르게 키보드 입력 패턴과 같은 개인 식별이 가능한 정보를 수집하고, 중국 업체의 서버와 직접 통신하는 기능이 포함되어 사용자의 채팅 기록이 외부로 유출될 가능성 제기 32)\n",
      "==================================================\n",
      "£ 딥시크는 중국의 규제 환경 속에서 운영되어 개인정보 처리 방식에 대한 의문을 유발 31)\n",
      "* 2025년  2월  9일,  국정원은  딥시크에  대한  기술  검증  결과  ▲과도한  개인정보  수집  ▲입력  데이터의  학습  데이터  활용 ▲광고주와의 무제한 정보 공유 ▲국외 서버 저장 등의 문제점을 확인했다고 밝힘\n",
      "==================================================\n",
      "£ 딥시크의 오픈소스 모델 버전에는 보안 취약점이 존재하여, 악의적인 행위자들에게 악용될 위험을 보유\n",
      "∙ 딥시크의 오픈소스 모델은 코드와 학습된 AI 모델이 공개되어 있어 누구나 접근하여 연구하고 사용할 수 있는 장점이 있지만, 동시에 악의적인 행위자들이 취약점을 분석하고 악용할 가능성도 내포\n",
      "∙ 2025년 1월 R1 모델이 공개된 이후 딥시크는 사이버공격을 경험하였고, 보안 취약점도 발견\n",
      "* 딥시크는  2025년  1월에  최신  오픈소스  모델인  R1  모델을  표적으로  삼은  심각한  분산  서비스  거부(DDoS)  공격을 경험하였으며, 이로 인해 딥시크 공식 웹사이트가 48시간 동안 다운됨 33)\n",
      "==================================================\n",
      "£ 딥시크의 오픈소스 모델 버전에는 보안 취약점이 존재하여, 악의적인 행위자들에게 악용될 위험을 보유\n",
      "* 2025년  1월  31일,  딥시크의  CDN  엔드포인트에서  크로스  사이트  스크립팅(XSS)  취약점이  확인되었으며,  이  취약점은 공격자가 적절한 출처 검증 없이 문서 컨텍스트에 악성 스크립트를 삽입할 수 있게 함 34)\n",
      "∙ 마이크로소프트(MS)는 애저(Azure)를 통해 딥시크의 'R1'을 서비스하며, 모델 동작에 대한 자동 평가 및 잠재적 위험 완화를 위한 광범위한 보안 검토와 함께 철저한 레드팀 및 안전 평가를 거쳤다고 강조 35)\n",
      "29) DeepSeek-AI, DeepSeek-R1 Release, 2025.1.20.\n",
      "30) SemiAnalysis, Seek Debates: Chinese Leadership On Cost, True Training Cost, Closed Model Margin Impacts, 2025.1.31.\n",
      "31) AP news, Italy blocks access to the Chinese AI application DeepSeek to protect users' data, 2025.1.31.\n",
      "==================================================\n",
      "£ 딥시크의 오픈소스 모델 버전에는 보안 취약점이 존재하여, 악의적인 행위자들에게 악용될 위험을 보유\n",
      "32) 국정원, 「딥시크」 서비스 활용시 보안유의 강조, 2025.2.9.\n",
      "33) Global Times, Cyberattacks against DeepSeek escalate with botnets joining, command surging over 100 times: lab, 2025.1.30.\n",
      "34) Cybernews, How Deepseek's security failures shape the future of cyber defense on AI, 2025.2.10.\n",
      "35) Microsoft, Securing DeepSeek and other AI systems with Microsoft Security, 2025.2.13.\n",
      "==================================================\n",
      "<주요국의 딥시크 규제 및 제한 현황>\n",
      "*출처:  소프트웨어정책연구소 정리(2025.2.16.)\n",
      "36) CNBC, NASA becomes latest federal agency to block China's DeepSeek on 'security and privacy concerns', 2025.1.31.\n",
      "37) AP news, House lawmakers push to ban AI app DeepSeek from US government devices, 2025.2.6.\n",
      "38) New York Post, New York bans DeepSeek from government devices over 'serious' data privacy, censorship concerns, 2025.2.10.\n",
      "39) euronews, DeepSeek: Which countries have restricted the Chinese AI company or are questioning it?, 2025.2.3.\n",
      "40) Reuters, DeepSeek may face further regulatory actions, EU privacy watchdog says, 2025.2.12.\n",
      "41) Reuters, Australia bans DeepSeek on government devices citing security concerns, 2025.2.5.\n",
      "42) Reuters, Taiwan says government departments should not use DeepSeek, citing security concerns, 2025.1.31.\n",
      "43) Kyodo News, Toyota, other major Japanese firms ban use of China's DeepSeek, 2025.2.12.\n",
      "44) 연합뉴스, 외교·산업부, 딥시크 접속 차단…카카오 등 기업도 '금지령', 2025.2.5.\n",
      "45) 서울경제, 서울대도 딥시크 주의보…\"개인정보 안전성 확인 전까지 접속차단\", 2025.2.13.\n",
      "==================================================\n",
      "£ (대규모  AI  모델  학습  방법의  전환  가능성)  딥시크는  MoE  등의  혁신적인  기술을  활용하여 AI  모델  학습  방식의  변화를  촉발할  수  있음\n",
      "∙ 미래의 AI 모델들은 연산 비용을 최소화하면서도 성능을 유지할 수 있는 유사한 최적화 기법을 도입하는 사례가 증가할 전망\n",
      "∙ 딥시크가 출시되기 전에 주요 AI 모델의 비용은 지난 2년 동안 연간 기준으로 이미 약 80% 하락했으며, 딥시크는 이러한 추세를 가속화할 것으로 예상\n",
      "*  출처:  reuters.com 46)\n",
      "<주요 AI  모델의 토큰 가격(단위: 달러/백만 토큰)>\n",
      "==================================================\n",
      "£ (새로운  최적화  기법의  확산)  딥시크의  강화학습  기법,  특히  GRPO  기법은  향후  AI  모델 개발에 상당한 영향을 미칠 수 있음\n",
      "∙ 혁신적인 강화학습 기반 기법은 AI 모델의 학습 효율성의 향상에 기여해 이러한 방식을 도입하는 AI 기업의 증가 예상\n",
      "∙ 콜드스타트 데이터 및 지식증류 기법은 최소한의 학습 데이터로도 AI 모델을 효율적으로 운영할 수 있도록 지원하여 산업 표준에 영향을 미칠 전망\n",
      "∙ 그러나 딥시크 R1 모델이 발표된 지 1달 이내인 현시점에서는 딥시크의 최적화 기법들이 전통적인 딥러닝 모델과 비교해 장기적으로 어떤 이점을 제공할지는 추가적인 실증적 검증이 필요한 상황\n",
      "==================================================\n",
      "£ (AI 산업계의  혁신  촉발)  딥시크의  AI  기술  혁신은  오픈AI,  구글,  앤스로픽과  기존의 선도적인 AI 기업의 전략에 상당한 영향을 미칠 전망\n",
      "∙ 딥시크가 PTX(Portable  Thread  Execution)*를  사용하여  엔비디아의  CUDA  라이브러리를  회피하고, GPU 최적화를 극대화한 사례는 향후 기업들의 AI 모델 개발 비용을 낮추는 효과를 가져올 전망\n",
      "*  다만, 딥시크가 사용한 PTX는 엔비디아가 개발한 저수준 프로그래밍 언어라는 점에서, 여전히 엔비디아 GPU 아키텍처에 의존할 가능성이 높음\n",
      "==================================================\n",
      "£ (AI 산업계의  혁신  촉발)  딥시크의  AI  기술  혁신은  오픈AI,  구글,  앤스로픽과  기존의 선도적인 AI 기업의 전략에 상당한 영향을 미칠 전망\n",
      "∙ 특히, AI 산업이 대규모 범용 모델 중심에서 벗어나 특정 산업 및 목적에 최적화된 맞춤형 AI 모델 개발로 이동할 것으로 예상되며, 이러한 흐름 속에서 오픈소스 AI 모델의 활용이 더욱 증가할 전망\n",
      "==================================================\n",
      "£ (AI  비즈니스  모델  변화  폐쇄형  모델  vs.  개방형  모델)  딥시크의  오픈소스  전략은  오픈AI 및 구글과 같은 폐쇄형 AI 모델 전략과 직접적인 경쟁 체계를 형성 가능\n",
      "∙ 딥시크가 경쟁력 있는 성능을 더 낮은 비용으로 제공할 경우, AI 산업 전반에서 오픈소스 친화적인 비즈니스 모델로 전환하는 기업들이 증가할 것으로 예상\n",
      "∙ 그러나 보안, 규제 준수, 특수 AI 애플리케이션이 필요한 산업(금융, 의료, 국방)에서는 폐쇄형 AI 모델이 향후 강력한 시장 입지를 유지할 가능성 존재\n",
      "==================================================\n",
      "£ (미국과  중국  간  AI  개발  경쟁의  가속화)  딥시크의  출현은  미국과  중국  간  AI  패권  경쟁을 가속화하는 요인으로 작용 가능\n",
      "∙ 오픈AI 및 구글이 서구 시장을 주도하는 반면, 딥시크를 필두로 한 중국의 AI 기업들은 아시아 및 신흥 경제국을 중심으로 영향력을 확대할 가능성 대두\n",
      "∙ 각국 정부는 기술 주권을 확보하기 위해 AI 연구 개발에 대한 투자를 더욱 강화할 가능성이 높으며, 글로벌 AI 거버넌스 구조에도 변화가 생길 가능성 존재\n",
      "==================================================\n",
      "£ (중국  AI  기업의  글로벌  시장  확장  가능성)  딥시크를  비롯한  중국  AI  기업들은  규제  및 지정학적 긴장에도 불구하고 국제 시장에서 영향력을 확대할 기회를 얻게 될 전망\n",
      "∙ 동남아, 중동, 아프리카 국가들은 미국 중심의 AI 기술에 대한 대안으로 중국 AI 기술을 채택할 가능성 존재\n",
      "∙ 다만, 데이터 보안, 국제 규제 준수, 정치적 검열 문제가 서구 시장에서 중국 AI 모델 확산을 저해하는 주요 요인이 될 것으로 예상\n",
      "==================================================\n",
      "£ (AI  기술  혁신  및  생태계  조성)  국내에서도  AI  기술  혁신을  위해  정부  차원의  R&D  투자  확대, AI  반도체와 연산 인프라 확보, 비용 절감형 AI 개발, 오픈소스 생태계 활성화 등의 전략이 필요\n",
      "∙ 주요국들은 AI 연구개발(R&D)에 매년 대규모 자금을 투입하고 있으며, 특히, 딥시크 등장의 영향으로 오픈소스 기반의 AI 생태계를 확대할 것으로 전망\n",
      "∙ 다수의 스타트업과 연구자들이 AI 모델을 개발할 수 있도록 오픈소스 AI 모델 개발·공유 생태계 활성화 필요\n",
      "∙ 국내에서도 스타트업의 초기 개발 비용과 연산 자원(GPU 등), 경쟁력 있는 AI 인재 확보 등의 어려움을 해소할 수 있도록 정부 차원의 기금 지원 및 AI 개발 인프라 제공이 필요\n",
      "==================================================\n",
      "£ (AI  기술  혁신  및  생태계  조성)  국내에서도  AI  기술  혁신을  위해  정부  차원의  R&D  투자  확대, AI  반도체와 연산 인프라 확보, 비용 절감형 AI 개발, 오픈소스 생태계 활성화 등의 전략이 필요\n",
      "∙ 딥시크가 엔비디아의 고가 GPU를 사용하지 않고도 비용을 절감한 사례를 고려할 때, 한국도 자체적인 AI 반도체 개발 및 저비용 고효율 AI 모델 개발에 투자 필요\n",
      "==================================================\n",
      "£ (글로벌  AI  협력  및  시장  진출  전략  다각화)  우리나라가  글로벌  AI  시장에서  주도적인 역할을 하기 위해서는 균형 잡힌 국제협력 전략과 적극적인 해외시장 개척이 필요\n",
      "∙ 중국과 미국이 AI 패권을 두고 경쟁하는 가운데, 한국은 AI 연구 협력과 시장 확장을 균형 있게 추진할 필요\n",
      "∙ AI  선진국(미국·유럽)과  협력하여  첨단  AI  기술  연구  및  AI  거버넌스  논의에  적극  참여하면서,  신흥 시장(동남아, 중동, 아프리카) 개척을 병행하는 전략 요구\n",
      "∙ 국내 기업들의 글로벌 AI 시장에서 경쟁력 확보를 위해 정부 차원의 지원(글로벌 네트워크 구축, 규제 대응 지원 등)이 필요\n",
      "==================================================\n",
      "£ (AI  신뢰·안전  거버넌스  구축)  우리나라  AI  산업의  지속적인  발전을  위해서는  신뢰성과  안전성을 갖춘 AI 거버넌스 체계 구축 필요\n",
      "∙ AI 기술이 빠르게 발전하면서, AI의 투명성, 공정성, 안전성 보장과 함께, 핵심 기술을 확보하여 국가 기술 주권을 강화하는 것이 필수적인 과제가 대두\n",
      "∙ 국내 AI 신뢰성을 확보하기 위해, 알고리즘의 투명성을 강화하고, AI 학습 데이터 품질 및 개인정보 보호 체계를 더 정교하게 구축 필요\n",
      "∙ 국제 및 지역별 AI 규제 흐름을 면밀히 분석하고, 변화하는 법적 요구 사항에 기민하게 대응할 수 있도록 유연하고 체계적인 법·제도적 기반을 마련할 필요\n",
      "==================================================\n",
      "[참고 문헌]\n",
      "1. AP news, House lawmakers push to ban AI app DeepSeek from US government devices, 2025.2.6.\n",
      "2. AP news, Italy blocks access to the Chinese AI application D eepSeek to protect users' data, 2025.1.31.\n",
      "3. Bain  &  Company,  DeepSeek:  A  Game  Changer  in  AI  Efficiency?,  2025.2.5.\n",
      "4. bruegel,  The  geopolitics  of  artificial  intelligence  after  DeepSeek,  2025.2.4.\n",
      "5. China  Daily,  DeepSeek's  AI  breakthrough  widely  recognized  by  US  tech  industry,  2025.2.12.\n",
      "6. CIO,  How  DeepSeek  changes  the  gen  AI  equation  for  CIOs,  2025.1.30.\n",
      "7. CNBC,  NASA  becomes  latest  federal  agency  to  block  China's  DeepSeek  on  'security  and privacy  concerns',  2025.1.31.\n",
      "8. Cybernews, How Deepseek's security failures shape the future of cyber defense on AI, 2025.02.10.\n",
      "9. DeepSeek-AI,  DeepSeek-R1:  Incentivizing  Reasoning  Capability  in  LLMs  via  Reinforcement Learning,  2025.1.22.\n",
      "10. DeepSeek-AI,  DeepSeek-R1  Release,  2025.1.20.\n",
      "11. DeepSeek-AI,  DeepSeek-V2:  A  Strong,  Economical,  and  Efficient  Mixture-of-Experts  Language Model,  2024.5.7.\n",
      "12. DeepSeek-AI,  DeepSeek-V3  Technical  Report,  2024.12.27.\n",
      "13. DeepSeek-AI,  DeepSeekMath:  Pushing  the  Limits  of  Mathematical  Reasoning  in  Open  Language Models, 2024.4.24.\n",
      "14. Deloitte,  딥시크가  촉발한  새로운  AI  경쟁시대,  2025.2.\n",
      "15. DLA  PIPER,  China  releases  AI  safety  governance  framework,  2024.09.12.\n",
      "16. euronews,  DeepSeek:  Which  countries  have  restricted  the  Chinese  AI  company  or  are questioning  it?,  2025.2.3.\n",
      "==================================================\n",
      "[참고 문헌]\n",
      "17. Financial  times,  Transcript: Tech in 2025 - China's AI 'Sputnik moment', 2025.1.30.\n",
      "18. Forbes,  Why DeepSeek's New AI Model Should Prompt Reality Checks For Companies, 2025. 1.29.\n",
      "19. Geop  litical  Monitor,  The Global AI Race: The Geopolitics of DeepSeek, 2025. 2.12.\n",
      "20. Global Times, Cyberattacks against DeepSeek escalate with botnets joining, command surging over 100 times: lab, 2025.1.30.\n",
      "21. IDC,  DeepSeek's  AI  Innovation:  A  Shift  in  AI  Model  Efficiency  and  Cost  Structure,  2025.1.31.\n",
      "22. Kyodo  News,  Toyota, other major Japanese firms ban use of China's DeepSeek, 2025.2.12.\n",
      "23. HAI,  How Disruptive Is DeepSeek? Stanford HAI Faculty Discuss China's New Model, 2025.2.13.\n",
      "24. Medium, Gemini 2.0 Pro vs DeepSeek R1: The AI Showdown Y ou Didn't Know Y ou Needed, 2025.2.6.\n",
      "25. Medium, Multi-head Latent Attention (MLA): Secret behind the success of DeepSeek Large Language Models, 2025.1.31.\n",
      "26. Microsoft, Securing DeepSeek and other AI systems with Microsoft Security, 2025.2.13.\n",
      "27. neptune.ai,  Knowledge  Distillation:  Principles,  Algorithms,  Applications,  2023.09.29.\n",
      "28. New  York  Post,  New  York  bans  DeepSeek  from  government  devices  over  'serious'  data privacy,  censorship  concerns,  2025.2.10.\n",
      "29. Reuters,  Australia bans DeepSeek on government devices citing security concerns,  2025.2.5.\n",
      "30. Reuters,  Chinese chip makers, cloud providers rush to embrace homegrown DeepSeek, 2025.2.5.\n",
      "31. Reuters,  DeepSeek may face further regulatory actions, EU privacy watchdog says,  2025.2.12.\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "32. Reuters,  Four ways DeepSeek could change everything,  2025.2.12.\n",
      "33. Reuters,  French privacy watchdog to quiz DeepSeek on AI, data protection,  2025.1.31.\n",
      "34. Reuters,  South  Korean  ministries  block  DeepSeek  on  security  concerns,  officials  say,  2025.2.6.\n",
      "35. Reuters, T aiw an says go vernm ent departm ents should not use D eepS eek, citing security c oncerns, 2025.1.31.\n",
      "36. Science  Media  Centre,  expert  reaction  to  new  AI  Chatbot  DeepSeek,  2025.1.28.\n",
      "37. SemiAnalysis,  Seek  Debates:  Chinese  Leadership  On  Cost,  True  Training  Cost,  Closed Model  Margin  Impacts,  2025.1.31.\n",
      "38. The Alan Turing Institute, B rief analysis of D eepS eek R 1 and its im plication s for G enerative A I, 2025.2.7.\n",
      "39. The  Wall  Street  Journal,  Six  Takeaways  From  a  Monumental  Week  for  AI,  2025.2.2.\n",
      "40. Xinhuanet, D eepSeek gains popularity in R ussia for high-quality content, accessibility: m edia, 2025.2.12.\n",
      "41. 국정원, 「딥시크」 서비스 활용시 보안유의 강조, 2025.2.9.\n",
      "42. 서울경제, 서울대도 딥시크 주의보…\"개인정보 안전성 확인 전까지 접속차단\", 2025.2.13.\n",
      "43. 연합뉴스, 외교·산업부, 딥시크 접속 차단…카카오 등 기업도 '금지령', 2025.2.5.\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "홈페이지 : https://spri.kr/ 보고서와 관련된 문의는 AI정책연구실(hs.lee@spri.kr, 031-739-7333)으로 연락주시기 바랍니다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a6539b",
   "metadata": {},
   "source": [
    "## 제너레이터 형태로 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac0865d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.lazy_load()  # 제너레이터 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90433602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narae/wanted/mcp_exercise/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AI브리프 스페셜] 딥시크(DeepSeek)의 등장과 영향\n",
      "-  Brief  Special -\n",
      "중국과 일본의 생성AI 동향 호 2025년  2월\n",
      "==================================================\n",
      "딥시크(DeepSeek)의 등장과 영향\n",
      "최근 중국의 스타트업인 딥시크는 DeepSeek-R1 모델을 출시하며 크게 주목받고 있다. 딥시크가 개발한 AI  모델은  중국  내에서는  AI  독립성을  강화하는  기술로  평가되고, 벤치마킹  결과  특정  작업에서  오픈AI의  GPT-4와  경쟁할  수  있는  성능을  보였다고 보고하지만, 국제적으로는 정책 검열, 보안, 개인정보보호 관련 우려가 제기된다. 미국, 유럽 등 여러 국가에서 데이터 보안 및 개인정보 보호 문제로 딥시크의 사용을 제한하는 조치가 확대되고 있다. 이러한 논란 속에서도 딥시크는 AI 시장의 새로운 경쟁 구도를 형성하고 있으며, 향후 글로벌 AI 산업의 변화에 중대한 영향을 미칠 것으로 전망된다.\n",
      "==================================================\n",
      "£ 2025년  1월  20일,  중국의  스타트업인  딥시크(창업자:  량원평)가  전세계  AI  산업계에  상당한 파급력을 갖는 DeepSeek-R1 모델(이하 R1 모델)을 출시 1)2)\n",
      "∙ 딥시크의 추론형 AI 모델 'R1'과 'R1-Zero'*는 AI 연구 커뮤니티와 업계 관계자들 사이에서 상당한 화제로 부상 3)\n",
      "* R1-Zero는  강화학습만으로  학습된  모델로  지도학습  기반  파인튜닝(Supervised  Fine-Tuning,  SFT)  없이  스스로  문제 해결하는  모델이며,  반면에  R1은  소량의  콜드스타트(Cold-start)  데이터와  다단계  학습  과정을  통해  더욱  향상된  성능과 가독성을 제공하는 모델\n",
      "==================================================\n",
      "£ 2025년  1월  20일,  중국의  스타트업인  딥시크(창업자:  량원평)가  전세계  AI  산업계에  상당한 파급력을 갖는 DeepSeek-R1 모델(이하 R1 모델)을 출시 1)2)\n",
      "∙ 딥시크는 R1 모델 발표와 함께 AI 산업에서 핵심 플레이어 중 하나로 빠르게 자리 잡아가고 있으며 가성비 높은 AI 모델로서의 입지를 구축해가는 추세\n",
      "==================================================\n",
      "£ 오픈AI 및 구글은  기반모델을  개발하여  폐쇄적인  형태로  운영하는  반면,  딥시크는 오픈소스 기반으로 R1 모델 개발 4)\n",
      "∙ 딥시크는 오픈소스 기반으로 지식 증류와 다단계 강화학습과 같은 비용 절감 기술을 도입하여 AI 모델의 효율성을 향상 5)\n",
      "∙ R1 모델은 AI 학습의 효율성을 극대화하기 위해 전문가 혼합(MoE, Mixture-of-Experts) 기술을 활용\n",
      "∙ 딥시크는 벤치마킹 평가 결과를 통해 R1 모델이 GPT-4 모델과 경쟁할 만한 성능을 기록했다고 주장\n",
      "1) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "2) Deloitte, 딥시크가 촉발한 새로운 AI 경쟁시대, 2025.2.\n",
      "3) Reuters, Chinese chip makers, cloud providers rush to embrace homegrown DeepSeek, 2025.2.5.\n",
      "==================================================\n",
      "£ 오픈AI 및 구글은  기반모델을  개발하여  폐쇄적인  형태로  운영하는  반면,  딥시크는 오픈소스 기반으로 R1 모델 개발 4)\n",
      "4) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "5) DeepSeek-AI, DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model, 2024.5.7.\n",
      "1\n",
      "==================================================\n",
      "£ 중국  정부가  AI  산업  진흥과  동시에  관련  보안  규제를  강화하는  환경에서  중국의 스타트업인  딥시크는  오픈AI,  구글,  메타  등  선도적인  AI  기업에  대한  의존도를  낮출  수 있는 AI 기술을 공개하였다고 평가 6)7)\n",
      "∙ 중국은 공격적으로 디지털 주권을 추구하며, AI 개발이 경제 성장, 사회적 안정, 전략적·군사적 이점을 포함한 국가적 우선순위와 일치하도록 엄격히 감독하고, 데이터 현지화, 알고리즘 등록 및 엄격한 콘텐츠 통제를 요구하는 정책을 시행 8)\n",
      "∙ R1 모델은 AI 기반모델 분야에서 중국이 미국 및 유럽과의 AI 기술 격차를 좁히는 데 핵심적인 역할을 할 것으로 평가\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "∙ 신화통신과 차이나데일리는 딥시크가 중국의 AI 독립성을 강화하는 데 기여하고 있다고 강조\n",
      "*  중국  인공지능(AI)  애플리케이션인 딥시크가 고품질 콘텐츠와 접근성으로 인해 러시아 사용자들에게 인기를 얻고 있음(신화통신 9) )\n",
      "*  중국  AI  기업  딥시크는  최근  획기적인  AI  모델을  선보이며  주요  미국  기술  회사로부터  긍정적인  반응을 얻음(차이나데일리) 10)\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "∙ 반면, 일부 서방 언론은 딥시크의 기술적 발전을 인정하면서도, 투명성, 데이터 출처, 중국의 AI 규제가 초래할 수 있는 잠재적 제한에 대한 우려를 제기\n",
      "* AI  회사인  딥시크는  모델이  학습되는  방식을  개선하여  방대한  컴퓨팅  중심  인프라에  의존하는  대신,  강화학습과  전문가 혼합(MoE)  아키텍처를 활용하여 컴퓨팅 수요를 줄이는 동시에 성능을 개선(IDC) 11)\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "*  '딥시크  팀은  오픈소스,  고성능  모델을  출시함으로써  중요한  이정표를  달성'(에든버러대  Luo  Mai  박사),  '미국  외에서  가장 경쟁력 있는 모델로 보임'(리즈 대학의 Anthony G Cohn 교수) 12)  등의 전문가 평가 존재\n",
      "*  프랑스의  개인정보  보호  기관인  CNIL은  딥시크의  AI  시스템이  개인정보에 미치는 영향을  조사할 계획 13)\n",
      "6) bruegel, The geopolitics of artificial intelligence after DeepSeek, 2025.2.4.\n",
      "7) DLA PIPER, China releases AI safety governance framework, 2024.09.12.\n",
      "8) Geop litical Monitor, The Global AI Race: The Geopolitics of DeepSeek, 2025. 2.12.\n",
      "9) Xinhuanet, DeepSeek gains popularity in Russia for high-quality content, accessibility: media, 2025.2.12.\n",
      "10) China Daily, DeepSeek's AI breakthrough widely recognized by US tech industry, 2025.2.12.\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "11) IDC, DeepSeek's AI Innovation: A Shift in AI Model Efficiency and Cost Structure, 2025.1.31\n",
      "12) Science Media Centre, expert reaction to new AI Chatbot DeepSeek, 2025.1.28.\n",
      "13) Reuters, French privacy watchdog to quiz DeepSeek on AI, data protection, 2025.1.31.\n",
      "==================================================\n",
      "£ 딥시크의 V3 모델은 전문가 혼합(Mixture-of-Experts, MoE) 아키텍처 기반한 언어모델로, 딥시크 R1 모델 개발을 위한 기초 모델(Basic Model)로 사용\n",
      "∙ V3  모델은  총  6,710억  개(671B)의  파라미터를  보유하고  있지만,  각  토큰을  처리할  때  활성화되는 파라미터는 370억 개(37B)만 사용하도록 설계\n",
      "∙ 총 14.8조 개의 고품질 데이터를 사용하여 사전학습하고, 지도학습 미세조정(Supervised Fine-Tuning)과 강화학습(Reinforcement Learning, RL)을 통해 모델의 성능을 극대화\n",
      "∙ 총 2.788M(278만 8천) H800 GPU 시간을 소요하여 학습을 완료(최신 AI 모델 중에서도 비교적 저렴한 비용으로 학습)\n",
      "==================================================\n",
      "£ 딥시크의 V3 모델은 전문가 혼합(Mixture-of-Experts, MoE) 아키텍처 기반한 언어모델로, 딥시크 R1 모델 개발을 위한 기초 모델(Basic Model)로 사용\n",
      "∙ V3 모델은 다른 오픈소스 모델보다 우수한 성능을 보이고, 폐쇄형 모델(예: OpenAI GPT-4 등)과 경쟁할 만한 성능을 기록\n",
      "==================================================\n",
      "<V3  모델의  주요  기술>\n",
      "MoE (Mixture-of-Experts), 주요내용 = ∙ V3모델은MoE를적용해특정작업에적합한신경망모듈만활성화함으로써연산효율성과응답품질을최적화 ∙ 특히, 기초모델을수학,코딩등특정작업에최적화된여러개의소규모전문가모델로나누어 학습부담을줄이는방식을적용 ∙ 딥시크가MoE 기술을적용하였다는측면에서는DeepSeek-V3의 아키텍처가완전히새로운 혁신이라기보다는기존연구의발전형태로볼수있다는평가도존재. MLA(Multi-head Latent Attention), 주요내용 = ∙ 딥시크의V3모델은기존MHA(Multi-head-Attention) 대비개선된MLA기술을적용하여더욱더 효율적으로정보를처리하고,계산속도를높이면서도메모리사용량을줄여추론을빠르게수행. 보조손실(auxiliary-loss) 없는로드밸런싱, 주요내용 = ∙ 기초적인 구조를 갖는 MoE 모델에서는 일반적으로 전문가 모델 간의 부하를 균등하게 분배 하기위해추가적인손실(loss)을 설정 ∙ 보조손실없는로드밸런싱을갖는V3는추가손실없이도효과적으로부하를분산하도록설계. 다중토큰예측(Multi-token Prediction), 주요내용 = ∙ 일반적인언어모델은한번에하나의토큰을예측하지만,V3모델은한번에여러개의토큰을 예측하는방식을적용하여성능을향상\n",
      "14) DeepSeek-AI, DeepSeek-V3 Technical Report, 2024.12.27.\n",
      "15) The Alan Turing Institute, Brief analysis of DeepSeek R1 and its implications for Generative AI, 2025.2.7.\n",
      "3\n",
      "==================================================\n",
      "<V3  모델  아키텍쳐>\n",
      "- *  출처:  DeepSeek-A,  DeepSeek-V3  Technical  ReportI 16)\n",
      "==================================================\n",
      "2)  DeepSeek-R1  -  추론(Reasoning) 17)18)\n",
      "£ (R1-Zero  모델  개발)  딥시크  연구팀은  순수  강화학습(Reinforcement  Learning,  RL)만을 활용하여  추론  능력을  향상하고,  자체적으로  진화하는  모델을  목표로  한  프로젝트에서 DeepSeek-R1-Zero(이하 R1-Zero) 모델을 개발\n",
      "∙ 딥시크의 연구팀은 개발 목표가 순수 RL 프로세스를 통해 자기 진화에 초점을 맞추어, 지도학습 데이터를 사용하지 않으면서 LLM이 추론 능력을 개발할 수 있는 잠재력을 탐구하는 것이었다고 설명\n",
      "∙ 특히,  모델의  추론  능력  향상을  위해  V3-base  모델(DeepSeek-V3-Base,  6,710억  파라미터)을 기반으로 하여 GRPO(Group Relative Policy Optimization) 기법*을 강화학습 프레임워크로 적용하여 R1-Zero 모델을 개발\n",
      "==================================================\n",
      "2)  DeepSeek-R1  -  추론(Reasoning) 17)18)\n",
      "16) DeepSeek-AI, DeepSeek-V3 Technical Report, 2024.12.27.\n",
      "17) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "18) The Alan Turing Institute, Brief analysis of DeepSeek R1 and its implications for Generative AI, 2025.2.7\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "*  GRPO(Generalized  Relative  Policy  Optimization):  대규모  언어  모델(LLM)에서  추론  능력을  강화하도록  설계된  강화학습 알고리즘으로,  비용이  많이  소요되며  평가자에  크게  의존하는  기존  강화학습  방법과  달리  GRPO는  응답  그룹을  서로  비교 평가하여 모델을 최적화\n",
      "∙ 일반적인 강화학습에서는 보통 정책 모델(Policy Model)과 비평 모델(Critic Model)을 함께 사용하여 학습을 진행하며, 비평 모델은 정책 모델과 같은 크기로 만들어야 하는 경우가 많아, 학습 비용이 매우 비싸지는 단점 존재\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "∙ V3 모델은 강화학습 비용을 절감하기 위해 GRPO 기법을 사용하여 별도의 비평 모델을 두지 않고, 대신 여러 개의 정답 후보(출력값)를 그룹으로 묶고, 여러 개의 답변을 비교하면서 상대적으로 더 좋은 답변을 학습\n",
      "==================================================\n",
      "<PPO와  GRPO  비교>\n",
      "*  출처:  DeepSeek-AI,  Tsinghua  University,  Peking  University 19)\n",
      "∙ R1-Zero 모델은 추론 및 수학적 문제 해결 성능이 향상*\n",
      "*  R1-Zero  모델  성능  개선:  ▲AIME  2024  벤치마크  성능  15.6%  →  71.0%▲강화학습의  다수결  투표(Majority  Voting)  기법 추가 후 86.7% 성능 도달(OpenAI o1-0912와 유사한 수준)\n",
      "∙ 그러나, R1-Zero 모델은 추론 및 수학적 문제 해결 성능의 우수성은 높았지만. 가독성(Readability)이 낮고 언어 혼합(Language Mixing) 등의 문제점 존재\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "∙ 딥시크 연구팀은 V3-Base 모델 미세조정을 위해 수천 개의 콜드스타트 데이터(Cold-start Data)*를 수집\n",
      "*  콜드스타트  데이터는  머신러닝  모델의  학습을  초기화하거나  \"킥스타트\"하는  데  사용되는  소량의  고품질  지도학습  데이터를 말하며, 특히 모델을 처음부터 학습하거나 새로운 작업으로 전환하는 시나리오에서 사용\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "∙ 이어 V3-Base 모델을 콜드스타트 데이터로 미세 조정하고, R1-Zero와 유사한 방식으로 대형 R1 모델에 강화학습 적용*\n",
      "*  특히  코딩,  수학,  과학,  논리적  사고(Logical  Reasoning)와  같은  명확한  정답이  있는  문제  해결  능력을  강화하는  데  집중\n",
      "∙ 강화학습  과정에서  연쇄적  사고(Chain  of  Thought,  CoT)  과정에서  여러  언어가  혼합되는  언어 혼합(Language Mixing 등의 문제점을 발견하여 보상 체계를 최적화하는 방식으로 해결*\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "*  강화학습  과정에서  여러  언어가  포함된  강화학습  프롬프트를  학습할  때  여러  언어가  혼합되는  문제가  발생하여  이러한  문제를 해결하기 위해 연쇄적 사고(CoT)에서 목표 언어의 비율을 계산하여 보상을 부여하는 방식을 적용\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "∙ 강화학습 과정이 일정 수준의 성능(수렴 단계)에 도달하면, 기존 모델의 성능을 보다 더 향상하기 위해 새로운 학습 데이터로 모델을 미세 조정하며, 이러한 과정은 다음과 같은 과정을 통해 수행\n",
      "① 거부 샘플링(Rejection Sampling): 강화학습을 통해 다양한 답변 중 품질이 높은 데이터만 선별\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "② 지도학습  미세조정(SFT)  데이터  추가:  ①에서  선별된  데이터와  기존  V3  모델에서  수집한  SFT 데이터(예: 글쓰기, 사실 기반 질의응답, 자기 인식 관련 데이터)와 결합\n",
      "③ 모델 재훈련(retrain): 새로운 데이터로 V3-Base 모델을 재학습시켜 더욱 정교한 AI 모델을 완성\n",
      "==================================================\n",
      "<거부 샘플링 및 지도학습 미세조정으로 수집된 추론 및 비 추론 학습 데이터>\n",
      "추론 데이터, 주요내용 = ∙ 추론프롬프트를수집,강화학습과정에서생성된체크포인트모델출력중품질높은데이터를선별해학습데이터로활용 ∙ 이전 단계에서 규칙 기반 보상(rule-based rewards)을 사용해 평가할 수 있는 데이터만 포함했지만, 이번 단계에서는추가데이터를포함하여데이터셋을확장 - 일부 데이터는 생성형 보상 모델(generative reward model)을 활용하여 평가되며, 이를 위해 정답 (Ground Truth)과 모델의예측결과를V3모델에입력하여평가 ∙ 모델이 생성한 답변이 혼란스럽거나 가독성이 낮은 경우를 방지하기 위해, 언어가 섞인 문장, 너무 긴 문단, 코드블록이포함된응답을필터링 ∙ 각프롬프트에대해여러개의응답을생성한후,정확한응답만남김 ∙ 최종적으로, 총60만개(600k)의 추론관련학습데이터를수집. 비추론 데이터, 주요내용 = ∙ 추론과\n",
      "==================================================\n",
      "<거부 샘플링 및 지도학습 미세조정으로 수집된 추론 및 비 추론 학습 데이터>\n",
      "관련이 없는 글쓰기, 사실 기반 질의응답(factual QA), 자기 인식(self-cognition), 번역 (translation) 등의 작업에서는 V3 모델의 기존 학습 데이터 파이프라인을 활용하고, V3의 모델의 지도학습 미세조정데이터셋을일부재사용 ∙ 특정비추론작업에서는V3모델을활용해먼저CoT(연쇄적사고)를생성한후답변을생성 ∙ 최종적으로, 총20만개(200k)의 비추론학습데이터를수집\n",
      "*  출처:  DeepSeek-AI\n",
      "==================================================\n",
      "<거부 샘플링 및 지도학습 미세조정으로 수집된 추론 및 비 추론 학습 데이터>\n",
      "- ∙ 모델에 대한 미세조정을 완료한 이후, 모델이 다양한 상황에서 더 나은 응답을 할 수 있도록 모든 종류의 프롬프트(질문이나 입력)를 반영하며 추가적인 강화학습을 수행하여 최종 R1 모델을 완성\n",
      "==================================================\n",
      "£ (R1  모델  연구의  중요한  발견  1)  강화학습  과정에서  R1-Zero  모델이  'aha  모멘트(아하 순간)'를 통해 문제 해결 방법을 탐색\n",
      "∙ 강화학습 프로세스는 R1-Zero 모델이 추론 과제를 해결하기 위해 더 많은 토큰(즉, 더 긴 사고 과정)을 생성하도록 하며, 테스트 시간 계산이 증가함에 따라 반성과 대안적 접근 방식에 대한 탐색과 같은 행동이 자연스럽게 발생(이러한 순간을 '아하 순간'이라 칭함)\n",
      "*  '아하  순간'이라는  용어는 중간  모델이 인간형 톤(tone)을  사용하여 재고하는 법을 배우는 순간에 기인\n",
      "==================================================\n",
      "£ (R1  모델  연구의  중요한  발견  1)  강화학습  과정에서  R1-Zero  모델이  'aha  모멘트(아하 순간)'를 통해 문제 해결 방법을 탐색\n",
      "∙ 딥시크 연구팀은 '아하 순간'은 모델이 자체적인 반성(self-reflection)을 통해 점진적으로 더 나은 답변을 생성하는 능력을 갖추고 있는지, 혹은 GPT 초기 모델이 글을 생성하는 방식과 유사하게 학습되는지를 연구할 필요가 있는 중요한 발견이라 설명\n",
      "==================================================\n",
      "£ (R1  모델  연구의  중요한  발견  2)  강화학습 과정에서 언어 일관성을 높이면 모델 성능이 감소\n",
      "∙ R1 모델을 연구하는 과정에서, 강화학습 프롬프트를 추가하여 언어 일관성을 높이려고 했을 때, 모델의 성능이 오히려 감소하는 현상 확인\n",
      "∙ 딥시크의 연구에서 언어의 가독성과 사용성을 강화하려는 과정에서 벤치마크 성능과의 균형을 유지해야 하는 문제가 발생하였으며, 최종적으로, AIME 2024 벤치마크에서 79.8%의 성능을 기록\n",
      "==================================================\n",
      "£ 딥시크 연구팀은 대형 모델(R1 모델)에서 작은 모델로 '지식 증류(Distillation)' 진행\n",
      "∙ 딥시크 연구팀은 R1 모델이 학습한 추론 패턴(논리적 사고 방식)을 더 작은 AI 모델에 압축하여 전이(지식 증류)하는 실험을 진행\n",
      "∙ 실험 결과, R1 모델에서 직접 지식 증류를 적용한 모델이 같은 모델에 강화학습을 적용한 것보다 더 좋은 성능을 보였음을 확인\n",
      "∙ 연구팀은 증류된 Qwen 모델에서 증류한 14B 모델이 기존의 최신 오픈소스 모델 QwQ-32B-Preview보다 훨씬 뛰어난 성능을 보였으며, Qwen 및 Llama로부터 각각 증류한 32B 모델 및 70B 모델은 추론 성능 부문에서 새로운 기록을 세웠다고 설명\n",
      "==================================================\n",
      "£ 딥시크 연구팀은 대형 모델(R1 모델)에서 작은 모델로 '지식 증류(Distillation)' 진행\n",
      "* R1-Distill-Qwen-32B  및  R1-Distill-Llama-70B는  코딩  및  수학적  추론과  관련된  작업에서  OpenAI의  o1-mini보다 우수한 성능을 보임\n",
      "==================================================\n",
      "<DeepSeek-R1  증류  모델과  타  모델과의 추론  관련  벤치마크 비교>\n",
      ",  = . , Cons264 = 26.7. , Pass21 = 78.3. ,  = 650. ,  = 38.4. ,  = 717. OpenAl-ol-mini,  = 636. OpenAl-ol-mini, Cons264 = . OpenAl-ol-mini, Pass21 = . OpenAl-ol-mini,  = . OpenAl-ol-mini,  = 53,0. OpenAl-ol-mini,  = 1820. QwQ-32B-Prview,  = . QwQ-32B-Prview, Cons264 = 6u.. QwQ-32B-Prview, Pass21 = . QwQ-32B-Prview,  = 54,5. QwQ-32B-Prview,  = 410. QwQ-32B-Prview,  = 1316. DeepSeek-RI-Distill-Qwen-LSB,  = . DeepSeek-RI-Distill-Qwen-LSB, Cons264 = . DeepSeek-RI-Distill-Qwen-LSB, Pass21 = 83,4. DeepSeek-RI-Distill-Qwen-LSB,  = 338. DeepSeek-RI-Distill-Qwen-LSB,  = 16.4. DeepSeek-RI-Distill-Qwen-LSB,  = 954. DeepSeek-RI-Dislill-Qwen-7B,  = 555. DeepSeek-RI-Dislill-Qwen-7B, Cons264 = 813. DeepSeek-RI-Dislill-Qwen-7B, Pass21 = 928. DeepSeek-RI-Dislill-Qwen-7B,  = 49.1. DeepSeek-RI-Dislill-Qwen-7B,  = . DeepSeek-RI-Dislill-Qwen-7B,  = . DeepSeek-RI-Distill-Qwen-I4B,\n",
      "==================================================\n",
      "<DeepSeek-R1  증류  모델과  타  모델과의 추론  관련  벤치마크 비교>\n",
      "= 647. DeepSeek-RI-Distill-Qwen-I4B, Cons264 = . DeepSeek-RI-Distill-Qwen-I4B, Pass21 = . DeepSeek-RI-Distill-Qwen-I4B,  = . DeepSeek-RI-Distill-Qwen-I4B,  = 53.1. DeepSeek-RI-Distill-Qwen-I4B,  = . DeepSeek-RI-Distill-Qwen-32B,  = 726. DeepSeek-RI-Distill-Qwen-32B, Cons264 = 833. DeepSeek-RI-Distill-Qwen-32B, Pass21 = . DeepSeek-RI-Distill-Qwen-32B,  = 621. DeepSeek-RI-Distill-Qwen-32B,  = 57.2. DeepSeek-RI-Distill-Qwen-32B,  = 169]. DeepSeek-RI-Distill-Llama-BB,  = . DeepSeek-RI-Distill-Llama-BB, Cons264 = . DeepSeek-RI-Distill-Llama-BB, Pass21 = 64.1. DeepSeek-RI-Distill-Llama-BB,  = 490. DeepSeek-RI-Distill-Llama-BB,  = 39.6. DeepSeek-RI-Distill-Llama-BB,  = 1205. ,  = . , Cons264 = 86.7. , Pass21 = 94.5. ,  = 65.2. ,  = 57.5. ,  = 1633\n",
      "*  출처:  DeekSeek-AI\n",
      "==================================================\n",
      "<지식 증류 개념도 예시>\n",
      "- **  딥시크가  이용한 지식증류 방법은 대규모 모델에서 작은 모델로 지식을 압축하여 성능 저하 없이 효율성을 극대화하는 기술\n",
      "==================================================\n",
      "£ DeepSeek  팀은  R1  모델이  가진  강력한  추론  능력을  더  작은  AI  모델에도  적용하기 위해,  Qwen과 Llama와 같은  오픈소스 모델을 활용하고, 증류 버전도 오픈소스로 공개\n",
      "∙ R1 모델이 학습한 80만 개(800k)의 고품질 데이터 샘플을 사용해 Qwen과 Llama 모델들에 대해 미세 조정을 수행\n",
      "∙ 딥시크 연구팀은 Qwen과 Llama 모델 시리즈의 증류 버전을 오픈소스로 공개\n",
      "20) neptune.ai, Knowledge Distillation: Principles, Algorithms, Applications, 2023.09.29.\n",
      "==================================================\n",
      "£ (연구  문제)  딥시크  연구팀은  R1-Zero  모델의  성공적인  결과를  바탕으로,  다음의  두  가지 문제를 해결하는 방안 연구\n",
      "∙ AI의  추론  능력을  더  높이고  학습  속도를  더  빠르게  하려고  고품질  데이터  일부를  초기  학습 데이터(cold-start data)로 추가하는 방법\n",
      "∙ 사용자 친화적인 AI 모델을 만들기 위해 AI가 명확하고 일관된 CoT(Chain of Thought, 연쇄적 사고)를 생성하면서도, 다양한 문제를 잘 해결할 수 있도록 학습하는 방법\n",
      "==================================================\n",
      "£ (해결  방안)  딥시크  연구팀은  연구  문제에  관해  R1  모델을  학습하기  위해  4단계로  구성된 강화학습 단계(파이프라인)을 설계\n",
      "- ∙ 1단계: 콜드스타트(Cold Start) → 2단계: 추론 지향 강화학습(Reasoning-oriented Reinforcement Learning)  →  3단계:  거부  샘플링  및  지도학습  미세조정(Rejection  Sampling  and  Supervised Fine-Tuning) → 4단계: 모든 시나리오를 위한 강화학습(Reinforcement Learning for all Scenarios)\n",
      "==================================================\n",
      "£ (콜드스타트  방법)  강화학습을  처음  시작할  때,  모델이  불안정한  상태에서  학습하는  문제를 방지하기 위해 R1  모델에서는  초기  학습  단계에서  소량의  고품질  콜드스타트  데이터(Cold Start  Data)를  먼저  학습하도록  설계\n",
      "∙ 초기 데이터를 수집하기 위해 연구팀은 ▲모델에 장문의 CoT 예제 제공, ▲세부적인 답변을 생성하도록 요청,  ▲가독성인  좋은  R1-Zero  모델의  출력  데이터를  활용,  ▲모델이  생성한  응답을  사람이  직접 수정하여 품질을 높임\n",
      "∙ 이와 같은 방식으로 수집한 수천 개의 콜드스타트 데이터를 활용해 V3-Base 모델을 먼저 미세 조정한 후 강화학습을 진행\n",
      "==================================================\n",
      "£ (콜드스타트 활용의 장점) 가독성(Readability) 및 성능(Potential)  항상\n",
      "∙ R1-Zero 모델은 여러 언어가 섞여 있고 가독성이 낮았으나, R1 모델은 응답 마지막에 요약을 추가하여 사용자 친화적인 출력 형식 제공\n",
      "∙ 사람이 직접 설계한 콜드스타트 데이터를 학습한 모델이 향상된 성능을 기록\n",
      "==================================================\n",
      "£ R1  모델은 특정 응용 분야에서 강점을 보이며, 현재 가장 발전된 AI 모델들과 경쟁 가능성 보유\n",
      "∙ 딥시크는 벤치마크 평가에서 R1 모델이 오픈AI의 o1 모델과 성능이 동등하거나 높으며, 비용은 o1 모델 대비 저렴하고, R1 모델의 기반이 된 V3 모델 학습 시 엔비디아 H100보다 성능이 절반 수준인 H800 2천 개를 사용하고, 학습 비용이 약 560만 달러에 불과했다고 주장 21)\n",
      "*  수학  관련  AIME  2024와  MATH-500  벤치마크에서  R1  모델은  각각  79.8%와  97.3%의  정확도로  o1  모델의  79.2%과 96.4%를 능가했으며, 기타 벤치마크에서도 o1 모델과 근소한 차이를 기록\n",
      "==================================================\n",
      "£ R1  모델은 특정 응용 분야에서 강점을 보이며, 현재 가장 발전된 AI 모델들과 경쟁 가능성 보유\n",
      "∙ 한편, 미국 기술 산업계 일부는 딥시크가 주장한 560만 달러는 전체 개발비의 일부일 뿐이며 H800 외에 고사양 GPU를 혼합하여 학습했을 수도 있다고 추측도 있음 22)\n",
      "==================================================\n",
      "<딥시크 R1 모델의 벤치마크 평가 결과>\n",
      "(좌측부터) 1)  AIME  2024:  미국수학협회(MAA)가  주관하는  수학  올림피아드 예선  문제\n",
      "2)  Codeforces:  전  세계  개발자들을  대상으로  하는  프로그래밍 대회  플랫폼\n",
      "3)  GPQA  Diamond:  AI  모델의  고급  추론  능력을  평가하기  위한  벤치마크\n",
      "4)  MATH-500:  수학적  추론과  문제  해결  능력을  평가\n",
      "5)  MMLU(Massive  Multitask  Language  Understanding):  다양한  학문  분야에서  AI의  작업  능력을  평가하는  벤치마크\n",
      "6)  SWE  Bench  Verified:  오픈AI에서  개발한  소프트웨어  엔지니어링  성능  평가  벤치마크\n",
      "*  출처:  deepseek;  medium.com 23)\n",
      "21) Forbes, Why DeepSeek's New AI Model Should Prompt Reality Checks For Companies, 2025. 1.29.\n",
      "22) Bain & Company, DeepSeek: A Game Changer in AI Efficiency?, 2025.2.5.\n",
      "23) Medium, Multi-head Latent Attention (MLA): Secret behind the success of DeepSeek Large Language Models, 2025.1.31.\n",
      "==================================================\n",
      "<딥시크 R1 모델의 벤치마크 평가 결과>\n",
      "- ∙ 한편,  글로벌  컨설팅사인  베인(Bain&Company)은  MMLU에  따른  LLM  비용의  추세를  분석하고, 딥시크의 이러한 비용 절감 결과는 AI 효율성의 추세와 일치하기에 그리 놀랍지 않으며, 더욱 놀라운 점은 중국 스타트업의 오픈소스 모델이 선도적인 독점 모델과의 격차를 상당히 좁히는 데 성공한 것이라고 평가\n",
      "==================================================\n",
      "<MMLU에서 백만 토큰당 가장 저렴한 LLM 비용(미국 달러, 로그 스케일)>\n",
      "- *  출처:  Bain&Company 24)\n",
      "==================================================\n",
      "2)  기술적  강점과  한계\n",
      "£ (강점)  딥시크는  중국어  자연어  처리에서  강점을  보이며,  컴퓨팅  인프라가  제한된  기업에도 적합하고, 유연한 오픈소스 전략으로 중국 AI 생태계 내에서 널리 채택\n",
      "∙ 딥시크는 자연어 처리 작업에서 우수한 성능을 보이며, 특히 중국어 기반 작업에서 두각을 나타냄 25)\n",
      "∙ 상대적으로 낮은 하드웨어 요구사항으로 컴퓨팅 인프라가 제한적인 기업에 적합 26)\n",
      "∙ 딥시크는 유연한 오픈소스 전략으로 중국 AI 생태계 내에서 광범위한 도입 진행 중\n",
      "==================================================\n",
      "2)  기술적  강점과  한계\n",
      "* BYD를  포함한  자동차  제조업체  8곳,  최소  9개의  금융증권  회사,  국유  통신  사업자  3곳이  딥시크와의  통합을  추진하고, 클라우드 컴퓨팅 사업자 알리바바, 화웨이, 텐센트, 바이두는 고객이 딥시크의 최신 모델을 이용하는 방법을 제공\n",
      "24) Bain & Company, DeepSeek: A Game Changer in AI Efficiency?, 2025.2.5.\n",
      "25) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "26)  Financial times, Transcript: Tech in 2025 - China's AI 'Sputnik moment', 2025.1.30.\n",
      "==================================================\n",
      "£ (한계) 딥시크는  텍스트  및  수치  데이터  처리에  강점을  갖지만,  멀티모달  기능이 제한적이며, 중국의 규제로 인해 정치적으로 민감한 주제에 대한 응답을 제한 27)28)\n",
      "∙ 딥시크는 주로 텍스트 및 수치 데이터 처리에 중점을 두어 멀티모달 기능이 제한적인 반면, 구글 Gemini는 텍스트, 이미지, 오디오, 비디오 입력을 처리할 수 있는 멀티모달 기능을 갖추고 있음\n",
      "∙ 딥시크는 중국의 규제 환경에서 운영되어 정치적으로 민감한 주제에 대한 응답이 제한적이므로 표현의 자유를 중시하는 국가에서는 딥시크의 도입에 대해 부정적일 수 있음\n",
      "==================================================\n",
      "£ 딥시크는  연구논문에서  MoE,  MLA 등의 기법을  활용하여  연산  자원  사용을 최적화하여 오픈AI의 GPT-4 등의 AI 모델 보다 학습비용이 낮다고 주장 29)\n",
      "∙ 그러나 일부에서는  딥시크가 비용 절감을 달성한 것으로 평가하면서도 인프라 및 인력 비용까지 고려했을 때 실제로는 보다 많이 비용이 들었을 수 있다고 추측\n",
      "*  독립적인  연구  기업인  SemiAnalysis는  딥시크의  600만  달러라는  추산은  주로  GPU  사전학습  비용을  고려하였으며,  회사에서 발생하는 연구 개발, 인프라 및 기타 필수 비용에 대한 상당한 투자는 무시되었다고 주장 30)\n",
      "==================================================\n",
      "£ 딥시크는 중국의 규제 환경 속에서 운영되어 개인정보 처리 방식에 대한 의문을 유발 31)\n",
      "∙ 중국의 사이버 보안법에 따르면, AI 기업들은 데이터를 국내에서 저장 및 처리해야 하며, 필요 시 정부 기관에 제공해야 하는 의무를 보유\n",
      "*  딥시크  약관에 수집된 데이터는 중국 내 서버에 저장되며 중국 정부의 요청 시 제공될 수 있도록 규정\n",
      "∙ 딥시크는 일반적인 생성AI와 다르게 키보드 입력 패턴과 같은 개인 식별이 가능한 정보를 수집하고, 중국 업체의 서버와 직접 통신하는 기능이 포함되어 사용자의 채팅 기록이 외부로 유출될 가능성 제기 32)\n",
      "==================================================\n",
      "£ 딥시크는 중국의 규제 환경 속에서 운영되어 개인정보 처리 방식에 대한 의문을 유발 31)\n",
      "* 2025년  2월  9일,  국정원은  딥시크에  대한  기술  검증  결과  ▲과도한  개인정보  수집  ▲입력  데이터의  학습  데이터  활용 ▲광고주와의 무제한 정보 공유 ▲국외 서버 저장 등의 문제점을 확인했다고 밝힘\n",
      "==================================================\n",
      "£ 딥시크의 오픈소스 모델 버전에는 보안 취약점이 존재하여, 악의적인 행위자들에게 악용될 위험을 보유\n",
      "∙ 딥시크의 오픈소스 모델은 코드와 학습된 AI 모델이 공개되어 있어 누구나 접근하여 연구하고 사용할 수 있는 장점이 있지만, 동시에 악의적인 행위자들이 취약점을 분석하고 악용할 가능성도 내포\n",
      "∙ 2025년 1월 R1 모델이 공개된 이후 딥시크는 사이버공격을 경험하였고, 보안 취약점도 발견\n",
      "* 딥시크는  2025년  1월에  최신  오픈소스  모델인  R1  모델을  표적으로  삼은  심각한  분산  서비스  거부(DDoS)  공격을 경험하였으며, 이로 인해 딥시크 공식 웹사이트가 48시간 동안 다운됨 33)\n",
      "==================================================\n",
      "£ 딥시크의 오픈소스 모델 버전에는 보안 취약점이 존재하여, 악의적인 행위자들에게 악용될 위험을 보유\n",
      "* 2025년  1월  31일,  딥시크의  CDN  엔드포인트에서  크로스  사이트  스크립팅(XSS)  취약점이  확인되었으며,  이  취약점은 공격자가 적절한 출처 검증 없이 문서 컨텍스트에 악성 스크립트를 삽입할 수 있게 함 34)\n",
      "∙ 마이크로소프트(MS)는 애저(Azure)를 통해 딥시크의 'R1'을 서비스하며, 모델 동작에 대한 자동 평가 및 잠재적 위험 완화를 위한 광범위한 보안 검토와 함께 철저한 레드팀 및 안전 평가를 거쳤다고 강조 35)\n",
      "29) DeepSeek-AI, DeepSeek-R1 Release, 2025.1.20.\n",
      "30) SemiAnalysis, Seek Debates: Chinese Leadership On Cost, True Training Cost, Closed Model Margin Impacts, 2025.1.31.\n",
      "31) AP news, Italy blocks access to the Chinese AI application DeepSeek to protect users' data, 2025.1.31.\n",
      "==================================================\n",
      "£ 딥시크의 오픈소스 모델 버전에는 보안 취약점이 존재하여, 악의적인 행위자들에게 악용될 위험을 보유\n",
      "32) 국정원, 「딥시크」 서비스 활용시 보안유의 강조, 2025.2.9.\n",
      "33) Global Times, Cyberattacks against DeepSeek escalate with botnets joining, command surging over 100 times: lab, 2025.1.30.\n",
      "34) Cybernews, How Deepseek's security failures shape the future of cyber defense on AI, 2025.2.10.\n",
      "35) Microsoft, Securing DeepSeek and other AI systems with Microsoft Security, 2025.2.13.\n",
      "==================================================\n",
      "<주요국의 딥시크 규제 및 제한 현황>\n",
      "*출처:  소프트웨어정책연구소 정리(2025.2.16.)\n",
      "36) CNBC, NASA becomes latest federal agency to block China's DeepSeek on 'security and privacy concerns', 2025.1.31.\n",
      "37) AP news, House lawmakers push to ban AI app DeepSeek from US government devices, 2025.2.6.\n",
      "38) New York Post, New York bans DeepSeek from government devices over 'serious' data privacy, censorship concerns, 2025.2.10.\n",
      "39) euronews, DeepSeek: Which countries have restricted the Chinese AI company or are questioning it?, 2025.2.3.\n",
      "40) Reuters, DeepSeek may face further regulatory actions, EU privacy watchdog says, 2025.2.12.\n",
      "41) Reuters, Australia bans DeepSeek on government devices citing security concerns, 2025.2.5.\n",
      "42) Reuters, Taiwan says government departments should not use DeepSeek, citing security concerns, 2025.1.31.\n",
      "43) Kyodo News, Toyota, other major Japanese firms ban use of China's DeepSeek, 2025.2.12.\n",
      "44) 연합뉴스, 외교·산업부, 딥시크 접속 차단…카카오 등 기업도 '금지령', 2025.2.5.\n",
      "45) 서울경제, 서울대도 딥시크 주의보…\"개인정보 안전성 확인 전까지 접속차단\", 2025.2.13.\n",
      "==================================================\n",
      "£ (대규모  AI  모델  학습  방법의  전환  가능성)  딥시크는  MoE  등의  혁신적인  기술을  활용하여 AI  모델  학습  방식의  변화를  촉발할  수  있음\n",
      "∙ 미래의 AI 모델들은 연산 비용을 최소화하면서도 성능을 유지할 수 있는 유사한 최적화 기법을 도입하는 사례가 증가할 전망\n",
      "∙ 딥시크가 출시되기 전에 주요 AI 모델의 비용은 지난 2년 동안 연간 기준으로 이미 약 80% 하락했으며, 딥시크는 이러한 추세를 가속화할 것으로 예상\n",
      "*  출처:  reuters.com 46)\n",
      "<주요 AI  모델의 토큰 가격(단위: 달러/백만 토큰)>\n",
      "==================================================\n",
      "£ (새로운  최적화  기법의  확산)  딥시크의  강화학습  기법,  특히  GRPO  기법은  향후  AI  모델 개발에 상당한 영향을 미칠 수 있음\n",
      "∙ 혁신적인 강화학습 기반 기법은 AI 모델의 학습 효율성의 향상에 기여해 이러한 방식을 도입하는 AI 기업의 증가 예상\n",
      "∙ 콜드스타트 데이터 및 지식증류 기법은 최소한의 학습 데이터로도 AI 모델을 효율적으로 운영할 수 있도록 지원하여 산업 표준에 영향을 미칠 전망\n",
      "∙ 그러나 딥시크 R1 모델이 발표된 지 1달 이내인 현시점에서는 딥시크의 최적화 기법들이 전통적인 딥러닝 모델과 비교해 장기적으로 어떤 이점을 제공할지는 추가적인 실증적 검증이 필요한 상황\n",
      "==================================================\n",
      "£ (AI 산업계의  혁신  촉발)  딥시크의  AI  기술  혁신은  오픈AI,  구글,  앤스로픽과  기존의 선도적인 AI 기업의 전략에 상당한 영향을 미칠 전망\n",
      "∙ 딥시크가 PTX(Portable  Thread  Execution)*를  사용하여  엔비디아의  CUDA  라이브러리를  회피하고, GPU 최적화를 극대화한 사례는 향후 기업들의 AI 모델 개발 비용을 낮추는 효과를 가져올 전망\n",
      "*  다만, 딥시크가 사용한 PTX는 엔비디아가 개발한 저수준 프로그래밍 언어라는 점에서, 여전히 엔비디아 GPU 아키텍처에 의존할 가능성이 높음\n",
      "==================================================\n",
      "£ (AI 산업계의  혁신  촉발)  딥시크의  AI  기술  혁신은  오픈AI,  구글,  앤스로픽과  기존의 선도적인 AI 기업의 전략에 상당한 영향을 미칠 전망\n",
      "∙ 특히, AI 산업이 대규모 범용 모델 중심에서 벗어나 특정 산업 및 목적에 최적화된 맞춤형 AI 모델 개발로 이동할 것으로 예상되며, 이러한 흐름 속에서 오픈소스 AI 모델의 활용이 더욱 증가할 전망\n",
      "==================================================\n",
      "£ (AI  비즈니스  모델  변화  폐쇄형  모델  vs.  개방형  모델)  딥시크의  오픈소스  전략은  오픈AI 및 구글과 같은 폐쇄형 AI 모델 전략과 직접적인 경쟁 체계를 형성 가능\n",
      "∙ 딥시크가 경쟁력 있는 성능을 더 낮은 비용으로 제공할 경우, AI 산업 전반에서 오픈소스 친화적인 비즈니스 모델로 전환하는 기업들이 증가할 것으로 예상\n",
      "∙ 그러나 보안, 규제 준수, 특수 AI 애플리케이션이 필요한 산업(금융, 의료, 국방)에서는 폐쇄형 AI 모델이 향후 강력한 시장 입지를 유지할 가능성 존재\n",
      "==================================================\n",
      "£ (미국과  중국  간  AI  개발  경쟁의  가속화)  딥시크의  출현은  미국과  중국  간  AI  패권  경쟁을 가속화하는 요인으로 작용 가능\n",
      "∙ 오픈AI 및 구글이 서구 시장을 주도하는 반면, 딥시크를 필두로 한 중국의 AI 기업들은 아시아 및 신흥 경제국을 중심으로 영향력을 확대할 가능성 대두\n",
      "∙ 각국 정부는 기술 주권을 확보하기 위해 AI 연구 개발에 대한 투자를 더욱 강화할 가능성이 높으며, 글로벌 AI 거버넌스 구조에도 변화가 생길 가능성 존재\n",
      "==================================================\n",
      "£ (중국  AI  기업의  글로벌  시장  확장  가능성)  딥시크를  비롯한  중국  AI  기업들은  규제  및 지정학적 긴장에도 불구하고 국제 시장에서 영향력을 확대할 기회를 얻게 될 전망\n",
      "∙ 동남아, 중동, 아프리카 국가들은 미국 중심의 AI 기술에 대한 대안으로 중국 AI 기술을 채택할 가능성 존재\n",
      "∙ 다만, 데이터 보안, 국제 규제 준수, 정치적 검열 문제가 서구 시장에서 중국 AI 모델 확산을 저해하는 주요 요인이 될 것으로 예상\n",
      "==================================================\n",
      "£ (AI  기술  혁신  및  생태계  조성)  국내에서도  AI  기술  혁신을  위해  정부  차원의  R&D  투자  확대, AI  반도체와 연산 인프라 확보, 비용 절감형 AI 개발, 오픈소스 생태계 활성화 등의 전략이 필요\n",
      "∙ 주요국들은 AI 연구개발(R&D)에 매년 대규모 자금을 투입하고 있으며, 특히, 딥시크 등장의 영향으로 오픈소스 기반의 AI 생태계를 확대할 것으로 전망\n",
      "∙ 다수의 스타트업과 연구자들이 AI 모델을 개발할 수 있도록 오픈소스 AI 모델 개발·공유 생태계 활성화 필요\n",
      "∙ 국내에서도 스타트업의 초기 개발 비용과 연산 자원(GPU 등), 경쟁력 있는 AI 인재 확보 등의 어려움을 해소할 수 있도록 정부 차원의 기금 지원 및 AI 개발 인프라 제공이 필요\n",
      "==================================================\n",
      "£ (AI  기술  혁신  및  생태계  조성)  국내에서도  AI  기술  혁신을  위해  정부  차원의  R&D  투자  확대, AI  반도체와 연산 인프라 확보, 비용 절감형 AI 개발, 오픈소스 생태계 활성화 등의 전략이 필요\n",
      "∙ 딥시크가 엔비디아의 고가 GPU를 사용하지 않고도 비용을 절감한 사례를 고려할 때, 한국도 자체적인 AI 반도체 개발 및 저비용 고효율 AI 모델 개발에 투자 필요\n",
      "==================================================\n",
      "£ (글로벌  AI  협력  및  시장  진출  전략  다각화)  우리나라가  글로벌  AI  시장에서  주도적인 역할을 하기 위해서는 균형 잡힌 국제협력 전략과 적극적인 해외시장 개척이 필요\n",
      "∙ 중국과 미국이 AI 패권을 두고 경쟁하는 가운데, 한국은 AI 연구 협력과 시장 확장을 균형 있게 추진할 필요\n",
      "∙ AI  선진국(미국·유럽)과  협력하여  첨단  AI  기술  연구  및  AI  거버넌스  논의에  적극  참여하면서,  신흥 시장(동남아, 중동, 아프리카) 개척을 병행하는 전략 요구\n",
      "∙ 국내 기업들의 글로벌 AI 시장에서 경쟁력 확보를 위해 정부 차원의 지원(글로벌 네트워크 구축, 규제 대응 지원 등)이 필요\n",
      "==================================================\n",
      "£ (AI  신뢰·안전  거버넌스  구축)  우리나라  AI  산업의  지속적인  발전을  위해서는  신뢰성과  안전성을 갖춘 AI 거버넌스 체계 구축 필요\n",
      "∙ AI 기술이 빠르게 발전하면서, AI의 투명성, 공정성, 안전성 보장과 함께, 핵심 기술을 확보하여 국가 기술 주권을 강화하는 것이 필수적인 과제가 대두\n",
      "∙ 국내 AI 신뢰성을 확보하기 위해, 알고리즘의 투명성을 강화하고, AI 학습 데이터 품질 및 개인정보 보호 체계를 더 정교하게 구축 필요\n",
      "∙ 국제 및 지역별 AI 규제 흐름을 면밀히 분석하고, 변화하는 법적 요구 사항에 기민하게 대응할 수 있도록 유연하고 체계적인 법·제도적 기반을 마련할 필요\n",
      "==================================================\n",
      "[참고 문헌]\n",
      "1. AP news, House lawmakers push to ban AI app DeepSeek from US government devices, 2025.2.6.\n",
      "2. AP news, Italy blocks access to the Chinese AI application D eepSeek to protect users' data, 2025.1.31.\n",
      "3. Bain  &  Company,  DeepSeek:  A  Game  Changer  in  AI  Efficiency?,  2025.2.5.\n",
      "4. bruegel,  The  geopolitics  of  artificial  intelligence  after  DeepSeek,  2025.2.4.\n",
      "5. China  Daily,  DeepSeek's  AI  breakthrough  widely  recognized  by  US  tech  industry,  2025.2.12.\n",
      "6. CIO,  How  DeepSeek  changes  the  gen  AI  equation  for  CIOs,  2025.1.30.\n",
      "7. CNBC,  NASA  becomes  latest  federal  agency  to  block  China's  DeepSeek  on  'security  and privacy  concerns',  2025.1.31.\n",
      "8. Cybernews, How Deepseek's security failures shape the future of cyber defense on AI, 2025.02.10.\n",
      "9. DeepSeek-AI,  DeepSeek-R1:  Incentivizing  Reasoning  Capability  in  LLMs  via  Reinforcement Learning,  2025.1.22.\n",
      "10. DeepSeek-AI,  DeepSeek-R1  Release,  2025.1.20.\n",
      "11. DeepSeek-AI,  DeepSeek-V2:  A  Strong,  Economical,  and  Efficient  Mixture-of-Experts  Language Model,  2024.5.7.\n",
      "12. DeepSeek-AI,  DeepSeek-V3  Technical  Report,  2024.12.27.\n",
      "13. DeepSeek-AI,  DeepSeekMath:  Pushing  the  Limits  of  Mathematical  Reasoning  in  Open  Language Models, 2024.4.24.\n",
      "14. Deloitte,  딥시크가  촉발한  새로운  AI  경쟁시대,  2025.2.\n",
      "15. DLA  PIPER,  China  releases  AI  safety  governance  framework,  2024.09.12.\n",
      "16. euronews,  DeepSeek:  Which  countries  have  restricted  the  Chinese  AI  company  or  are questioning  it?,  2025.2.3.\n",
      "==================================================\n",
      "[참고 문헌]\n",
      "17. Financial  times,  Transcript: Tech in 2025 - China's AI 'Sputnik moment', 2025.1.30.\n",
      "18. Forbes,  Why DeepSeek's New AI Model Should Prompt Reality Checks For Companies, 2025. 1.29.\n",
      "19. Geop  litical  Monitor,  The Global AI Race: The Geopolitics of DeepSeek, 2025. 2.12.\n",
      "20. Global Times, Cyberattacks against DeepSeek escalate with botnets joining, command surging over 100 times: lab, 2025.1.30.\n",
      "21. IDC,  DeepSeek's  AI  Innovation:  A  Shift  in  AI  Model  Efficiency  and  Cost  Structure,  2025.1.31.\n",
      "22. Kyodo  News,  Toyota, other major Japanese firms ban use of China's DeepSeek, 2025.2.12.\n",
      "23. HAI,  How Disruptive Is DeepSeek? Stanford HAI Faculty Discuss China's New Model, 2025.2.13.\n",
      "24. Medium, Gemini 2.0 Pro vs DeepSeek R1: The AI Showdown Y ou Didn't Know Y ou Needed, 2025.2.6.\n",
      "25. Medium, Multi-head Latent Attention (MLA): Secret behind the success of DeepSeek Large Language Models, 2025.1.31.\n",
      "26. Microsoft, Securing DeepSeek and other AI systems with Microsoft Security, 2025.2.13.\n",
      "27. neptune.ai,  Knowledge  Distillation:  Principles,  Algorithms,  Applications,  2023.09.29.\n",
      "28. New  York  Post,  New  York  bans  DeepSeek  from  government  devices  over  'serious'  data privacy,  censorship  concerns,  2025.2.10.\n",
      "29. Reuters,  Australia bans DeepSeek on government devices citing security concerns,  2025.2.5.\n",
      "30. Reuters,  Chinese chip makers, cloud providers rush to embrace homegrown DeepSeek, 2025.2.5.\n",
      "31. Reuters,  DeepSeek may face further regulatory actions, EU privacy watchdog says,  2025.2.12.\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "32. Reuters,  Four ways DeepSeek could change everything,  2025.2.12.\n",
      "33. Reuters,  French privacy watchdog to quiz DeepSeek on AI, data protection,  2025.1.31.\n",
      "34. Reuters,  South  Korean  ministries  block  DeepSeek  on  security  concerns,  officials  say,  2025.2.6.\n",
      "35. Reuters, T aiw an says go vernm ent departm ents should not use D eepS eek, citing security c oncerns, 2025.1.31.\n",
      "36. Science  Media  Centre,  expert  reaction  to  new  AI  Chatbot  DeepSeek,  2025.1.28.\n",
      "37. SemiAnalysis,  Seek  Debates:  Chinese  Leadership  On  Cost,  True  Training  Cost,  Closed Model  Margin  Impacts,  2025.1.31.\n",
      "38. The Alan Turing Institute, B rief analysis of D eepS eek R 1 and its im plication s for G enerative A I, 2025.2.7.\n",
      "39. The  Wall  Street  Journal,  Six  Takeaways  From  a  Monumental  Week  for  AI,  2025.2.2.\n",
      "40. Xinhuanet, D eepSeek gains popularity in R ussia for high-quality content, accessibility: m edia, 2025.2.12.\n",
      "41. 국정원, 「딥시크」 서비스 활용시 보안유의 강조, 2025.2.9.\n",
      "42. 서울경제, 서울대도 딥시크 주의보…\"개인정보 안전성 확인 전까지 접속차단\", 2025.2.13.\n",
      "43. 연합뉴스, 외교·산업부, 딥시크 접속 차단…카카오 등 기업도 '금지령', 2025.2.5.\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "홈페이지 : https://spri.kr/ 보고서와 관련된 문의는 AI정책연구실(hs.lee@spri.kr, 031-739-7333)으로 연락주시기 바랍니다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0008c6b",
   "metadata": {},
   "source": [
    "## Chunking까지 한번에 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac36a3",
   "metadata": {},
   "source": [
    "**HybridChunker** 는 문장, 문단 구조와 토큰 수를 함께 고려해서 문서를 잘게 나누는 도구입니다.\n",
    "\n",
    "tokenizer를 설정하면, 임베딩 모델의 토큰 길이를 고려해 의미 단위가 끊기지 않도록 적절한 크기로 나눌 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbbfa972",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/narae/wanted/mcp_exercise/.venv/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "from docling.chunking import HybridChunker\n",
    "from langchain_docling.loader import ExportType\n",
    "from langchain_docling import DoclingLoader\n",
    "\n",
    "FILE_PATH = \"/Users/narae/wanted/mcp_exercise/03_RAG_stdio/resources/SPRi AI Brief_Special_딥시크(DeepSeek)의 등장과 영향.pdf\"\n",
    "EXPORT_TYPE = ExportType.DOC_CHUNKS\n",
    "EMBED_MODEL_ID = \"BAAI/bge-m3\"\n",
    "\n",
    "loader = DoclingLoader(\n",
    "    file_path=FILE_PATH,\n",
    "    export_type=EXPORT_TYPE,\n",
    "    chunker=HybridChunker(tokenizer=EMBED_MODEL_ID),\n",
    ")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f87404f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AI브리프 스페셜] 딥시크(DeepSeek)의 등장과 영향\n",
      "-  Brief  Special -\n",
      "중국과 일본의 생성AI 동향 호 2025년  2월\n",
      "['#/texts/2', '#/texts/3']\n",
      "==================================================\n",
      "딥시크(DeepSeek)의 등장과 영향\n",
      "최근 중국의 스타트업인 딥시크는 DeepSeek-R1 모델을 출시하며 크게 주목받고 있다. 딥시크가 개발한 AI  모델은  중국  내에서는  AI  독립성을  강화하는  기술로  평가되고, 벤치마킹  결과  특정  작업에서  오픈AI의  GPT-4와  경쟁할  수  있는  성능을  보였다고 보고하지만, 국제적으로는 정책 검열, 보안, 개인정보보호 관련 우려가 제기된다. 미국, 유럽 등 여러 국가에서 데이터 보안 및 개인정보 보호 문제로 딥시크의 사용을 제한하는 조치가 확대되고 있다. 이러한 논란 속에서도 딥시크는 AI 시장의 새로운 경쟁 구도를 형성하고 있으며, 향후 글로벌 AI 산업의 변화에 중대한 영향을 미칠 것으로 전망된다.\n",
      "['#/texts/7']\n",
      "==================================================\n",
      "£ 2025년  1월  20일,  중국의  스타트업인  딥시크(창업자:  량원평)가  전세계  AI  산업계에  상당한 파급력을 갖는 DeepSeek-R1 모델(이하 R1 모델)을 출시 1)2)\n",
      "∙ 딥시크의 추론형 AI 모델 'R1'과 'R1-Zero'*는 AI 연구 커뮤니티와 업계 관계자들 사이에서 상당한 화제로 부상 3)\n",
      "* R1-Zero는  강화학습만으로  학습된  모델로  지도학습  기반  파인튜닝(Supervised  Fine-Tuning,  SFT)  없이  스스로  문제 해결하는  모델이며,  반면에  R1은  소량의  콜드스타트(Cold-start)  데이터와  다단계  학습  과정을  통해  더욱  향상된  성능과 가독성을 제공하는 모델\n",
      "∙ 딥시크는 R1 모델 발표와 함께 AI 산업에서 핵심 플레이어 중 하나로 빠르게 자리 잡아가고 있으며 가성비 높은 AI 모델로서의 입지를 구축해가는 추세\n",
      "['#/texts/10', '#/texts/11', '#/texts/12']\n",
      "==================================================\n",
      "£ 오픈AI 및 구글은  기반모델을  개발하여  폐쇄적인  형태로  운영하는  반면,  딥시크는 오픈소스 기반으로 R1 모델 개발 4)\n",
      "∙ 딥시크는 오픈소스 기반으로 지식 증류와 다단계 강화학습과 같은 비용 절감 기술을 도입하여 AI 모델의 효율성을 향상 5)\n",
      "∙ R1 모델은 AI 학습의 효율성을 극대화하기 위해 전문가 혼합(MoE, Mixture-of-Experts) 기술을 활용\n",
      "∙ 딥시크는 벤치마킹 평가 결과를 통해 R1 모델이 GPT-4 모델과 경쟁할 만한 성능을 기록했다고 주장\n",
      "1) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "2) Deloitte, 딥시크가 촉발한 새로운 AI 경쟁시대, 2025.2.\n",
      "3) Reuters, Chinese chip makers, cloud providers rush to embrace homegrown DeepSeek, 2025.2.5.\n",
      "4) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "5) DeepSeek-AI, DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model, 2024.5.7.\n",
      "1\n",
      "['#/texts/14', '#/texts/15', '#/texts/16', '#/texts/17', '#/texts/18', '#/texts/19', '#/texts/20', '#/texts/21', '#/texts/22']\n",
      "==================================================\n",
      "£ 중국  정부가  AI  산업  진흥과  동시에  관련  보안  규제를  강화하는  환경에서  중국의 스타트업인  딥시크는  오픈AI,  구글,  메타  등  선도적인  AI  기업에  대한  의존도를  낮출  수 있는 AI 기술을 공개하였다고 평가 6)7)\n",
      "∙ 중국은 공격적으로 디지털 주권을 추구하며, AI 개발이 경제 성장, 사회적 안정, 전략적·군사적 이점을 포함한 국가적 우선순위와 일치하도록 엄격히 감독하고, 데이터 현지화, 알고리즘 등록 및 엄격한 콘텐츠 통제를 요구하는 정책을 시행 8)\n",
      "∙ R1 모델은 AI 기반모델 분야에서 중국이 미국 및 유럽과의 AI 기술 격차를 좁히는 데 핵심적인 역할을 할 것으로 평가\n",
      "['#/texts/25', '#/texts/26']\n",
      "==================================================\n",
      "£ 중국 내 언론들은 딥시크에 대한 긍정적인 보도가 많지만, 서방 언론들은 다양한 시각이 존재\n",
      "∙ 신화통신과 차이나데일리는 딥시크가 중국의 AI 독립성을 강화하는 데 기여하고 있다고 강조\n",
      "*  중국  인공지능(AI)  애플리케이션인 딥시크가 고품질 콘텐츠와 접근성으로 인해 러시아 사용자들에게 인기를 얻고 있음(신화통신 9) )\n",
      "*  중국  AI  기업  딥시크는  최근  획기적인  AI  모델을  선보이며  주요  미국  기술  회사로부터  긍정적인  반응을 얻음(차이나데일리) 10)\n",
      "∙ 반면, 일부 서방 언론은 딥시크의 기술적 발전을 인정하면서도, 투명성, 데이터 출처, 중국의 AI 규제가 초래할 수 있는 잠재적 제한에 대한 우려를 제기\n",
      "* AI  회사인  딥시크는  모델이  학습되는  방식을  개선하여  방대한  컴퓨팅  중심  인프라에  의존하는  대신,  강화학습과  전문가 혼합(MoE)  아키텍처를 활용하여 컴퓨팅 수요를 줄이는 동시에 성능을 개선(IDC) 11)\n",
      "*  '딥시크  팀은  오픈소스,  고성능  모델을  출시함으로써  중요한  이정표를  달성'(에든버러대  Luo  Mai  박사),  '미국  외에서  가장 경쟁력 있는 모델로 보임'(리즈 대학의 Anthony G Cohn 교수) 12)  등의 전문가 평가 존재\n",
      "*  프랑스의  개인정보  보호  기관인  CNIL은  딥시크의  AI  시스템이  개인정보에 미치는 영향을  조사할 계획 13)\n",
      "6) bruegel, The geopolitics of artificial intelligence after DeepSeek, 2025.2.4.\n",
      "7) DLA PIPER, China releases AI safety governance framework, 2024.09.12.\n",
      "8) Geop litical Monitor, The Global AI Race: The Geopolitics of DeepSeek, 2025. 2.12.\n",
      "9) Xinhuanet, DeepSeek gains popularity in Russia for high-quality content, accessibility: media, 2025.2.12.\n",
      "10) China Daily, DeepSeek's AI breakthrough widely recognized by US tech industry, 2025.2.12.\n",
      "11) IDC, DeepSeek's AI Innovation: A Shift in AI Model Efficiency and Cost Structure, 2025.1.31\n",
      "12) Science Media Centre, expert reaction to new AI Chatbot DeepSeek, 2025.1.28.\n",
      "13) Reuters, French privacy watchdog to quiz DeepSeek on AI, data protection, 2025.1.31.\n",
      "['#/texts/28', '#/texts/29', '#/texts/30', '#/texts/31', '#/texts/32', '#/texts/33', '#/texts/34', '#/texts/35', '#/texts/36', '#/texts/37', '#/texts/38', '#/texts/39', '#/texts/40', '#/texts/41', '#/texts/42']\n",
      "==================================================\n",
      "£ 딥시크의 V3 모델은 전문가 혼합(Mixture-of-Experts, MoE) 아키텍처 기반한 언어모델로, 딥시크 R1 모델 개발을 위한 기초 모델(Basic Model)로 사용\n",
      "∙ V3  모델은  총  6,710억  개(671B)의  파라미터를  보유하고  있지만,  각  토큰을  처리할  때  활성화되는 파라미터는 370억 개(37B)만 사용하도록 설계\n",
      "∙ 총 14.8조 개의 고품질 데이터를 사용하여 사전학습하고, 지도학습 미세조정(Supervised Fine-Tuning)과 강화학습(Reinforcement Learning, RL)을 통해 모델의 성능을 극대화\n",
      "∙ 총 2.788M(278만 8천) H800 GPU 시간을 소요하여 학습을 완료(최신 AI 모델 중에서도 비교적 저렴한 비용으로 학습)\n",
      "∙ V3 모델은 다른 오픈소스 모델보다 우수한 성능을 보이고, 폐쇄형 모델(예: OpenAI GPT-4 등)과 경쟁할 만한 성능을 기록\n",
      "['#/texts/48', '#/texts/49', '#/texts/50', '#/texts/51']\n",
      "==================================================\n",
      "<V3  모델의  주요  기술>\n",
      "MoE (Mixture-of-Experts), 주요내용 = ∙ V3모델은MoE를적용해특정작업에적합한신경망모듈만활성화함으로써연산효율성과응답품질을최적화 ∙ 특히, 기초모델을수학,코딩등특정작업에최적화된여러개의소규모전문가모델로나누어 학습부담을줄이는방식을적용 ∙ 딥시크가MoE 기술을적용하였다는측면에서는DeepSeek-V3의 아키텍처가완전히새로운 혁신이라기보다는기존연구의발전형태로볼수있다는평가도존재. MLA(Multi-head Latent Attention), 주요내용 = ∙ 딥시크의V3모델은기존MHA(Multi-head-Attention) 대비개선된MLA기술을적용하여더욱더 효율적으로정보를처리하고,계산속도를높이면서도메모리사용량을줄여추론을빠르게수행. 보조손실(auxiliary-loss) 없는로드밸런싱, 주요내용 = ∙ 기초적인 구조를 갖는 MoE 모델에서는 일반적으로 전문가 모델 간의 부하를 균등하게 분배 하기위해추가적인손실(loss)을 설정 ∙ 보조손실없는로드밸런싱을갖는V3는추가손실없이도효과적으로부하를분산하도록설계. 다중토큰예측(Multi-token Prediction), 주요내용 = ∙ 일반적인언어모델은한번에하나의토큰을예측하지만,V3모델은한번에여러개의토큰을 예측하는방식을적용하여성능을향상\n",
      "14) DeepSeek-AI, DeepSeek-V3 Technical Report, 2024.12.27.\n",
      "15) The Alan Turing Institute, Brief analysis of DeepSeek R1 and its implications for Generative AI, 2025.2.7.\n",
      "3\n",
      "['#/tables/0', '#/texts/54', '#/texts/55', '#/texts/56']\n",
      "==================================================\n",
      "<V3  모델  아키텍쳐>\n",
      "- *  출처:  DeepSeek-A,  DeepSeek-V3  Technical  ReportI 16)\n",
      "['#/texts/61']\n",
      "==================================================\n",
      "2)  DeepSeek-R1  -  추론(Reasoning) 17)18)\n",
      "£ (R1-Zero  모델  개발)  딥시크  연구팀은  순수  강화학습(Reinforcement  Learning,  RL)만을 활용하여  추론  능력을  향상하고,  자체적으로  진화하는  모델을  목표로  한  프로젝트에서 DeepSeek-R1-Zero(이하 R1-Zero) 모델을 개발\n",
      "∙ 딥시크의 연구팀은 개발 목표가 순수 RL 프로세스를 통해 자기 진화에 초점을 맞추어, 지도학습 데이터를 사용하지 않으면서 LLM이 추론 능력을 개발할 수 있는 잠재력을 탐구하는 것이었다고 설명\n",
      "∙ 특히,  모델의  추론  능력  향상을  위해  V3-base  모델(DeepSeek-V3-Base,  6,710억  파라미터)을 기반으로 하여 GRPO(Group Relative Policy Optimization) 기법*을 강화학습 프레임워크로 적용하여 R1-Zero 모델을 개발\n",
      "16) DeepSeek-AI, DeepSeek-V3 Technical Report, 2024.12.27.\n",
      "17) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "18) The Alan Turing Institute, Brief analysis of DeepSeek R1 and its implications for Generative AI, 2025.2.7\n",
      "['#/texts/63', '#/texts/64', '#/texts/65', '#/texts/66', '#/texts/67', '#/texts/68']\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "*  GRPO(Generalized  Relative  Policy  Optimization):  대규모  언어  모델(LLM)에서  추론  능력을  강화하도록  설계된  강화학습 알고리즘으로,  비용이  많이  소요되며  평가자에  크게  의존하는  기존  강화학습  방법과  달리  GRPO는  응답  그룹을  서로  비교 평가하여 모델을 최적화\n",
      "∙ 일반적인 강화학습에서는 보통 정책 모델(Policy Model)과 비평 모델(Critic Model)을 함께 사용하여 학습을 진행하며, 비평 모델은 정책 모델과 같은 크기로 만들어야 하는 경우가 많아, 학습 비용이 매우 비싸지는 단점 존재\n",
      "∙ V3 모델은 강화학습 비용을 절감하기 위해 GRPO 기법을 사용하여 별도의 비평 모델을 두지 않고, 대신 여러 개의 정답 후보(출력값)를 그룹으로 묶고, 여러 개의 답변을 비교하면서 상대적으로 더 좋은 답변을 학습\n",
      "['#/texts/71', '#/texts/72', '#/texts/73']\n",
      "==================================================\n",
      "<PPO와  GRPO  비교>\n",
      "*  출처:  DeepSeek-AI,  Tsinghua  University,  Peking  University 19)\n",
      "∙ R1-Zero 모델은 추론 및 수학적 문제 해결 성능이 향상*\n",
      "*  R1-Zero  모델  성능  개선:  ▲AIME  2024  벤치마크  성능  15.6%  →  71.0%▲강화학습의  다수결  투표(Majority  Voting)  기법 추가 후 86.7% 성능 도달(OpenAI o1-0912와 유사한 수준)\n",
      "∙ 그러나, R1-Zero 모델은 추론 및 수학적 문제 해결 성능의 우수성은 높았지만. 가독성(Readability)이 낮고 언어 혼합(Language Mixing) 등의 문제점 존재\n",
      "['#/texts/82', '#/texts/83', '#/texts/84', '#/texts/85']\n",
      "==================================================\n",
      "£ (R1  모델로의  발전)  딥시크는  R1-Zero  모델의  가독성과  언어  혼합의  문제점을  개선하기 위해  지도학습  미세조정(SFT)  기법을  일부  재도입하고  R1-Zero  모델  개선을  지속하여 최종적으로 R1 모델을 개발\n",
      "∙ 딥시크 연구팀은 V3-Base 모델 미세조정을 위해 수천 개의 콜드스타트 데이터(Cold-start Data)*를 수집\n",
      "*  콜드스타트  데이터는  머신러닝  모델의  학습을  초기화하거나  \"킥스타트\"하는  데  사용되는  소량의  고품질  지도학습  데이터를 말하며, 특히 모델을 처음부터 학습하거나 새로운 작업으로 전환하는 시나리오에서 사용\n",
      "∙ 이어 V3-Base 모델을 콜드스타트 데이터로 미세 조정하고, R1-Zero와 유사한 방식으로 대형 R1 모델에 강화학습 적용*\n",
      "*  특히  코딩,  수학,  과학,  논리적  사고(Logical  Reasoning)와  같은  명확한  정답이  있는  문제  해결  능력을  강화하는  데  집중\n",
      "∙ 강화학습  과정에서  연쇄적  사고(Chain  of  Thought,  CoT)  과정에서  여러  언어가  혼합되는  언어 혼합(Language Mixing 등의 문제점을 발견하여 보상 체계를 최적화하는 방식으로 해결*\n",
      "*  강화학습  과정에서  여러  언어가  포함된  강화학습  프롬프트를  학습할  때  여러  언어가  혼합되는  문제가  발생하여  이러한  문제를 해결하기 위해 연쇄적 사고(CoT)에서 목표 언어의 비율을 계산하여 보상을 부여하는 방식을 적용\n",
      "∙ 강화학습 과정이 일정 수준의 성능(수렴 단계)에 도달하면, 기존 모델의 성능을 보다 더 향상하기 위해 새로운 학습 데이터로 모델을 미세 조정하며, 이러한 과정은 다음과 같은 과정을 통해 수행\n",
      "① 거부 샘플링(Rejection Sampling): 강화학습을 통해 다양한 답변 중 품질이 높은 데이터만 선별\n",
      "② 지도학습  미세조정(SFT)  데이터  추가:  ①에서  선별된  데이터와  기존  V3  모델에서  수집한  SFT 데이터(예: 글쓰기, 사실 기반 질의응답, 자기 인식 관련 데이터)와 결합\n",
      "③ 모델 재훈련(retrain): 새로운 데이터로 V3-Base 모델을 재학습시켜 더욱 정교한 AI 모델을 완성\n",
      "['#/texts/90', '#/texts/91', '#/texts/92', '#/texts/93', '#/texts/94', '#/texts/95', '#/texts/96', '#/texts/97', '#/texts/98', '#/texts/99']\n",
      "==================================================\n",
      "<거부 샘플링 및 지도학습 미세조정으로 수집된 추론 및 비 추론 학습 데이터>\n",
      "추론 데이터, 주요내용 = ∙ 추론프롬프트를수집,강화학습과정에서생성된체크포인트모델출력중품질높은데이터를선별해학습데이터로활용 ∙ 이전 단계에서 규칙 기반 보상(rule-based rewards)을 사용해 평가할 수 있는 데이터만 포함했지만, 이번 단계에서는추가데이터를포함하여데이터셋을확장 - 일부 데이터는 생성형 보상 모델(generative reward model)을 활용하여 평가되며, 이를 위해 정답 (Ground Truth)과 모델의예측결과를V3모델에입력하여평가 ∙ 모델이 생성한 답변이 혼란스럽거나 가독성이 낮은 경우를 방지하기 위해, 언어가 섞인 문장, 너무 긴 문단, 코드블록이포함된응답을필터링 ∙ 각프롬프트에대해여러개의응답을생성한후,정확한응답만남김 ∙ 최종적으로, 총60만개(600k)의 추론관련학습데이터를수집. 비추론 데이터, 주요내용 = ∙ 추론과 관련이 없는 글쓰기, 사실 기반 질의응답(factual QA), 자기 인식(self-cognition), 번역 (translation) 등의 작업에서는 V3 모델의 기존 학습 데이터 파이프라인을 활용하고, V3의 모델의 지도학습 미세조정데이터셋을일부재사용 ∙ 특정비추론작업에서는V3모델을활용해먼저CoT(연쇄적사고)를생성한후답변을생성 ∙ 최종적으로, 총20만개(200k)의 비추론학습데이터를수집\n",
      "*  출처:  DeepSeek-AI\n",
      "- ∙ 모델에 대한 미세조정을 완료한 이후, 모델이 다양한 상황에서 더 나은 응답을 할 수 있도록 모든 종류의 프롬프트(질문이나 입력)를 반영하며 추가적인 강화학습을 수행하여 최종 R1 모델을 완성\n",
      "['#/tables/1', '#/texts/101', '#/texts/104']\n",
      "==================================================\n",
      "£ (R1  모델  연구의  중요한  발견  1)  강화학습  과정에서  R1-Zero  모델이  'aha  모멘트(아하 순간)'를 통해 문제 해결 방법을 탐색\n",
      "∙ 강화학습 프로세스는 R1-Zero 모델이 추론 과제를 해결하기 위해 더 많은 토큰(즉, 더 긴 사고 과정)을 생성하도록 하며, 테스트 시간 계산이 증가함에 따라 반성과 대안적 접근 방식에 대한 탐색과 같은 행동이 자연스럽게 발생(이러한 순간을 '아하 순간'이라 칭함)\n",
      "*  '아하  순간'이라는  용어는 중간  모델이 인간형 톤(tone)을  사용하여 재고하는 법을 배우는 순간에 기인\n",
      "∙ 딥시크 연구팀은 '아하 순간'은 모델이 자체적인 반성(self-reflection)을 통해 점진적으로 더 나은 답변을 생성하는 능력을 갖추고 있는지, 혹은 GPT 초기 모델이 글을 생성하는 방식과 유사하게 학습되는지를 연구할 필요가 있는 중요한 발견이라 설명\n",
      "['#/texts/106', '#/texts/107', '#/texts/108']\n",
      "==================================================\n",
      "£ (R1  모델  연구의  중요한  발견  2)  강화학습 과정에서 언어 일관성을 높이면 모델 성능이 감소\n",
      "∙ R1 모델을 연구하는 과정에서, 강화학습 프롬프트를 추가하여 언어 일관성을 높이려고 했을 때, 모델의 성능이 오히려 감소하는 현상 확인\n",
      "∙ 딥시크의 연구에서 언어의 가독성과 사용성을 강화하려는 과정에서 벤치마크 성능과의 균형을 유지해야 하는 문제가 발생하였으며, 최종적으로, AIME 2024 벤치마크에서 79.8%의 성능을 기록\n",
      "['#/texts/110', '#/texts/111']\n",
      "==================================================\n",
      "£ 딥시크 연구팀은 대형 모델(R1 모델)에서 작은 모델로 '지식 증류(Distillation)' 진행\n",
      "∙ 딥시크 연구팀은 R1 모델이 학습한 추론 패턴(논리적 사고 방식)을 더 작은 AI 모델에 압축하여 전이(지식 증류)하는 실험을 진행\n",
      "∙ 실험 결과, R1 모델에서 직접 지식 증류를 적용한 모델이 같은 모델에 강화학습을 적용한 것보다 더 좋은 성능을 보였음을 확인\n",
      "∙ 연구팀은 증류된 Qwen 모델에서 증류한 14B 모델이 기존의 최신 오픈소스 모델 QwQ-32B-Preview보다 훨씬 뛰어난 성능을 보였으며, Qwen 및 Llama로부터 각각 증류한 32B 모델 및 70B 모델은 추론 성능 부문에서 새로운 기록을 세웠다고 설명\n",
      "* R1-Distill-Qwen-32B  및  R1-Distill-Llama-70B는  코딩  및  수학적  추론과  관련된  작업에서  OpenAI의  o1-mini보다 우수한 성능을 보임\n",
      "['#/texts/114', '#/texts/115', '#/texts/116', '#/texts/117']\n",
      "==================================================\n",
      "<DeepSeek-R1  증류  모델과  타  모델과의 추론  관련  벤치마크 비교>\n",
      ",  = . , Cons264 = 26.7. , Pass21 = 78.3. ,  = 650. ,  = 38.4. ,  = 717. OpenAl-ol-mini,  = 636. OpenAl-ol-mini, Cons264 = . OpenAl-ol-mini, Pass21 = . OpenAl-ol-mini,  = . OpenAl-ol-mini,  = 53,0. OpenAl-ol-mini,  = 1820. QwQ-32B-Prview,  = . QwQ-32B-Prview, Cons264 = 6u.. QwQ-32B-Prview, Pass21 = . QwQ-32B-Prview,  = 54,5. QwQ-32B-Prview,  = 410. QwQ-32B-Prview,  = 1316. DeepSeek-RI-Distill-Qwen-LSB,  = . DeepSeek-RI-Distill-Qwen-LSB, Cons264 = . DeepSeek-RI-Distill-Qwen-LSB, Pass21 = 83,4. DeepSeek-RI-Distill-Qwen-LSB,  = 338. DeepSeek-RI-Distill-Qwen-LSB,  = 16.4. DeepSeek-RI-Distill-Qwen-LSB,  = 954. DeepSeek-RI-Dislill-Qwen-7B,  = 555. DeepSeek-RI-Dislill-Qwen-7B, Cons264 = 813. DeepSeek-RI-Dislill-Qwen-7B, Pass21 = 928. DeepSeek-RI-Dislill-Qwen-7B,  = 49.1. DeepSeek-RI-Dislill-Qwen-7B,  = . DeepSeek-RI-Dislill-Qwen-7B,  = . DeepSeek-RI-Distill-Qwen-I4B,  = 647. DeepSeek-RI-Distill-Qwen-I4B, Cons264 = . DeepSeek-RI-Distill-Qwen-I4B, Pass21 = . DeepSeek-RI-Distill-Qwen-I4B,  = . DeepSeek-RI-Distill-Qwen-I4B,  = 53.1. DeepSeek-RI-Distill-Qwen-I4B,  = . DeepSeek-RI-Distill-Qwen-32B,  = 726. DeepSeek-RI-Distill-Qwen-32B, Cons264 = 833. DeepSeek-RI-Distill-Qwen-32B, Pass21 = . DeepSeek-RI-Distill-Qwen-32B,  = 621. DeepSeek-RI-Distill-Qwen-32B,  = 57.2. DeepSeek-RI-Distill-Qwen-32B,  = 169]. DeepSeek-RI-Distill-Llama-BB,  = . DeepSeek-RI-Distill-Llama-BB, Cons264 = . DeepSeek-RI-Distill-Llama-BB, Pass21 = 64.1. DeepSeek-RI-Distill-Llama-BB,  = 490. DeepSeek-RI-Distill-Llama-BB,  = 39.6. DeepSeek-RI-Distill-Llama-BB,  = 1205. ,  = . , Cons264 = 86.7. , Pass21 = 94.5. ,  = 65.2. ,  = 57.5. ,  = 1633\n",
      "*  출처:  DeekSeek-AI\n",
      "['#/tables/2', '#/texts/121']\n",
      "==================================================\n",
      "<지식 증류 개념도 예시>\n",
      "- **  딥시크가  이용한 지식증류 방법은 대규모 모델에서 작은 모델로 지식을 압축하여 성능 저하 없이 효율성을 극대화하는 기술\n",
      "['#/texts/124']\n",
      "==================================================\n",
      "£ DeepSeek  팀은  R1  모델이  가진  강력한  추론  능력을  더  작은  AI  모델에도  적용하기 위해,  Qwen과 Llama와 같은  오픈소스 모델을 활용하고, 증류 버전도 오픈소스로 공개\n",
      "∙ R1 모델이 학습한 80만 개(800k)의 고품질 데이터 샘플을 사용해 Qwen과 Llama 모델들에 대해 미세 조정을 수행\n",
      "∙ 딥시크 연구팀은 Qwen과 Llama 모델 시리즈의 증류 버전을 오픈소스로 공개\n",
      "20) neptune.ai, Knowledge Distillation: Principles, Algorithms, Applications, 2023.09.29.\n",
      "['#/texts/126', '#/texts/127', '#/texts/128']\n",
      "==================================================\n",
      "£ (연구  문제)  딥시크  연구팀은  R1-Zero  모델의  성공적인  결과를  바탕으로,  다음의  두  가지 문제를 해결하는 방안 연구\n",
      "∙ AI의  추론  능력을  더  높이고  학습  속도를  더  빠르게  하려고  고품질  데이터  일부를  초기  학습 데이터(cold-start data)로 추가하는 방법\n",
      "∙ 사용자 친화적인 AI 모델을 만들기 위해 AI가 명확하고 일관된 CoT(Chain of Thought, 연쇄적 사고)를 생성하면서도, 다양한 문제를 잘 해결할 수 있도록 학습하는 방법\n",
      "['#/texts/133', '#/texts/134']\n",
      "==================================================\n",
      "£ (해결  방안)  딥시크  연구팀은  연구  문제에  관해  R1  모델을  학습하기  위해  4단계로  구성된 강화학습 단계(파이프라인)을 설계\n",
      "- ∙ 1단계: 콜드스타트(Cold Start) → 2단계: 추론 지향 강화학습(Reasoning-oriented Reinforcement Learning)  →  3단계:  거부  샘플링  및  지도학습  미세조정(Rejection  Sampling  and  Supervised Fine-Tuning) → 4단계: 모든 시나리오를 위한 강화학습(Reinforcement Learning for all Scenarios)\n",
      "['#/texts/136']\n",
      "==================================================\n",
      "£ (콜드스타트  방법)  강화학습을  처음  시작할  때,  모델이  불안정한  상태에서  학습하는  문제를 방지하기 위해 R1  모델에서는  초기  학습  단계에서  소량의  고품질  콜드스타트  데이터(Cold Start  Data)를  먼저  학습하도록  설계\n",
      "∙ 초기 데이터를 수집하기 위해 연구팀은 ▲모델에 장문의 CoT 예제 제공, ▲세부적인 답변을 생성하도록 요청,  ▲가독성인  좋은  R1-Zero  모델의  출력  데이터를  활용,  ▲모델이  생성한  응답을  사람이  직접 수정하여 품질을 높임\n",
      "∙ 이와 같은 방식으로 수집한 수천 개의 콜드스타트 데이터를 활용해 V3-Base 모델을 먼저 미세 조정한 후 강화학습을 진행\n",
      "['#/texts/138', '#/texts/139']\n",
      "==================================================\n",
      "£ (콜드스타트 활용의 장점) 가독성(Readability) 및 성능(Potential)  항상\n",
      "∙ R1-Zero 모델은 여러 언어가 섞여 있고 가독성이 낮았으나, R1 모델은 응답 마지막에 요약을 추가하여 사용자 친화적인 출력 형식 제공\n",
      "∙ 사람이 직접 설계한 콜드스타트 데이터를 학습한 모델이 향상된 성능을 기록\n",
      "['#/texts/141', '#/texts/142']\n",
      "==================================================\n",
      "£ R1  모델은 특정 응용 분야에서 강점을 보이며, 현재 가장 발전된 AI 모델들과 경쟁 가능성 보유\n",
      "∙ 딥시크는 벤치마크 평가에서 R1 모델이 오픈AI의 o1 모델과 성능이 동등하거나 높으며, 비용은 o1 모델 대비 저렴하고, R1 모델의 기반이 된 V3 모델 학습 시 엔비디아 H100보다 성능이 절반 수준인 H800 2천 개를 사용하고, 학습 비용이 약 560만 달러에 불과했다고 주장 21)\n",
      "*  수학  관련  AIME  2024와  MATH-500  벤치마크에서  R1  모델은  각각  79.8%와  97.3%의  정확도로  o1  모델의  79.2%과 96.4%를 능가했으며, 기타 벤치마크에서도 o1 모델과 근소한 차이를 기록\n",
      "∙ 한편, 미국 기술 산업계 일부는 딥시크가 주장한 560만 달러는 전체 개발비의 일부일 뿐이며 H800 외에 고사양 GPU를 혼합하여 학습했을 수도 있다고 추측도 있음 22)\n",
      "['#/texts/148', '#/texts/149', '#/texts/150']\n",
      "==================================================\n",
      "<딥시크 R1 모델의 벤치마크 평가 결과>\n",
      "(좌측부터) 1)  AIME  2024:  미국수학협회(MAA)가  주관하는  수학  올림피아드 예선  문제\n",
      "2)  Codeforces:  전  세계  개발자들을  대상으로  하는  프로그래밍 대회  플랫폼\n",
      "3)  GPQA  Diamond:  AI  모델의  고급  추론  능력을  평가하기  위한  벤치마크\n",
      "4)  MATH-500:  수학적  추론과  문제  해결  능력을  평가\n",
      "5)  MMLU(Massive  Multitask  Language  Understanding):  다양한  학문  분야에서  AI의  작업  능력을  평가하는  벤치마크\n",
      "6)  SWE  Bench  Verified:  오픈AI에서  개발한  소프트웨어  엔지니어링  성능  평가  벤치마크\n",
      "*  출처:  deepseek;  medium.com 23)\n",
      "21) Forbes, Why DeepSeek's New AI Model Should Prompt Reality Checks For Companies, 2025. 1.29.\n",
      "22) Bain & Company, DeepSeek: A Game Changer in AI Efficiency?, 2025.2.5.\n",
      "23) Medium, Multi-head Latent Attention (MLA): Secret behind the success of DeepSeek Large Language Models, 2025.1.31.\n",
      "- ∙ 한편,  글로벌  컨설팅사인  베인(Bain&Company)은  MMLU에  따른  LLM  비용의  추세를  분석하고, 딥시크의 이러한 비용 절감 결과는 AI 효율성의 추세와 일치하기에 그리 놀랍지 않으며, 더욱 놀라운 점은 중국 스타트업의 오픈소스 모델이 선도적인 독점 모델과의 격차를 상당히 좁히는 데 성공한 것이라고 평가\n",
      "['#/texts/152', '#/texts/153', '#/texts/154', '#/texts/155', '#/texts/156', '#/texts/157', '#/texts/158', '#/texts/159', '#/texts/160', '#/texts/161', '#/texts/164']\n",
      "==================================================\n",
      "<MMLU에서 백만 토큰당 가장 저렴한 LLM 비용(미국 달러, 로그 스케일)>\n",
      "- *  출처:  Bain&Company 24)\n",
      "['#/texts/176']\n",
      "==================================================\n",
      "2)  기술적  강점과  한계\n",
      "£ (강점)  딥시크는  중국어  자연어  처리에서  강점을  보이며,  컴퓨팅  인프라가  제한된  기업에도 적합하고, 유연한 오픈소스 전략으로 중국 AI 생태계 내에서 널리 채택\n",
      "∙ 딥시크는 자연어 처리 작업에서 우수한 성능을 보이며, 특히 중국어 기반 작업에서 두각을 나타냄 25)\n",
      "∙ 상대적으로 낮은 하드웨어 요구사항으로 컴퓨팅 인프라가 제한적인 기업에 적합 26)\n",
      "∙ 딥시크는 유연한 오픈소스 전략으로 중국 AI 생태계 내에서 광범위한 도입 진행 중\n",
      "* BYD를  포함한  자동차  제조업체  8곳,  최소  9개의  금융증권  회사,  국유  통신  사업자  3곳이  딥시크와의  통합을  추진하고, 클라우드 컴퓨팅 사업자 알리바바, 화웨이, 텐센트, 바이두는 고객이 딥시크의 최신 모델을 이용하는 방법을 제공\n",
      "24) Bain & Company, DeepSeek: A Game Changer in AI Efficiency?, 2025.2.5.\n",
      "25) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "26)  Financial times, Transcript: Tech in 2025 - China's AI 'Sputnik moment', 2025.1.30.\n",
      "['#/texts/178', '#/texts/179', '#/texts/180', '#/texts/181', '#/texts/182', '#/texts/183', '#/texts/184', '#/texts/185']\n",
      "==================================================\n",
      "£ (한계) 딥시크는  텍스트  및  수치  데이터  처리에  강점을  갖지만,  멀티모달  기능이 제한적이며, 중국의 규제로 인해 정치적으로 민감한 주제에 대한 응답을 제한 27)28)\n",
      "∙ 딥시크는 주로 텍스트 및 수치 데이터 처리에 중점을 두어 멀티모달 기능이 제한적인 반면, 구글 Gemini는 텍스트, 이미지, 오디오, 비디오 입력을 처리할 수 있는 멀티모달 기능을 갖추고 있음\n",
      "∙ 딥시크는 중국의 규제 환경에서 운영되어 정치적으로 민감한 주제에 대한 응답이 제한적이므로 표현의 자유를 중시하는 국가에서는 딥시크의 도입에 대해 부정적일 수 있음\n",
      "['#/texts/189', '#/texts/190']\n",
      "==================================================\n",
      "£ 딥시크는  연구논문에서  MoE,  MLA 등의 기법을  활용하여  연산  자원  사용을 최적화하여 오픈AI의 GPT-4 등의 AI 모델 보다 학습비용이 낮다고 주장 29)\n",
      "∙ 그러나 일부에서는  딥시크가 비용 절감을 달성한 것으로 평가하면서도 인프라 및 인력 비용까지 고려했을 때 실제로는 보다 많이 비용이 들었을 수 있다고 추측\n",
      "*  독립적인  연구  기업인  SemiAnalysis는  딥시크의  600만  달러라는  추산은  주로  GPU  사전학습  비용을  고려하였으며,  회사에서 발생하는 연구 개발, 인프라 및 기타 필수 비용에 대한 상당한 투자는 무시되었다고 주장 30)\n",
      "['#/texts/196', '#/texts/197']\n",
      "==================================================\n",
      "£ 딥시크는 중국의 규제 환경 속에서 운영되어 개인정보 처리 방식에 대한 의문을 유발 31)\n",
      "∙ 중국의 사이버 보안법에 따르면, AI 기업들은 데이터를 국내에서 저장 및 처리해야 하며, 필요 시 정부 기관에 제공해야 하는 의무를 보유\n",
      "*  딥시크  약관에 수집된 데이터는 중국 내 서버에 저장되며 중국 정부의 요청 시 제공될 수 있도록 규정\n",
      "∙ 딥시크는 일반적인 생성AI와 다르게 키보드 입력 패턴과 같은 개인 식별이 가능한 정보를 수집하고, 중국 업체의 서버와 직접 통신하는 기능이 포함되어 사용자의 채팅 기록이 외부로 유출될 가능성 제기 32)\n",
      "* 2025년  2월  9일,  국정원은  딥시크에  대한  기술  검증  결과  ▲과도한  개인정보  수집  ▲입력  데이터의  학습  데이터  활용 ▲광고주와의 무제한 정보 공유 ▲국외 서버 저장 등의 문제점을 확인했다고 밝힘\n",
      "['#/texts/199', '#/texts/200', '#/texts/201', '#/texts/202']\n",
      "==================================================\n",
      "£ 딥시크의 오픈소스 모델 버전에는 보안 취약점이 존재하여, 악의적인 행위자들에게 악용될 위험을 보유\n",
      "∙ 딥시크의 오픈소스 모델은 코드와 학습된 AI 모델이 공개되어 있어 누구나 접근하여 연구하고 사용할 수 있는 장점이 있지만, 동시에 악의적인 행위자들이 취약점을 분석하고 악용할 가능성도 내포\n",
      "∙ 2025년 1월 R1 모델이 공개된 이후 딥시크는 사이버공격을 경험하였고, 보안 취약점도 발견\n",
      "* 딥시크는  2025년  1월에  최신  오픈소스  모델인  R1  모델을  표적으로  삼은  심각한  분산  서비스  거부(DDoS)  공격을 경험하였으며, 이로 인해 딥시크 공식 웹사이트가 48시간 동안 다운됨 33)\n",
      "* 2025년  1월  31일,  딥시크의  CDN  엔드포인트에서  크로스  사이트  스크립팅(XSS)  취약점이  확인되었으며,  이  취약점은 공격자가 적절한 출처 검증 없이 문서 컨텍스트에 악성 스크립트를 삽입할 수 있게 함 34)\n",
      "∙ 마이크로소프트(MS)는 애저(Azure)를 통해 딥시크의 'R1'을 서비스하며, 모델 동작에 대한 자동 평가 및 잠재적 위험 완화를 위한 광범위한 보안 검토와 함께 철저한 레드팀 및 안전 평가를 거쳤다고 강조 35)\n",
      "29) DeepSeek-AI, DeepSeek-R1 Release, 2025.1.20.\n",
      "30) SemiAnalysis, Seek Debates: Chinese Leadership On Cost, True Training Cost, Closed Model Margin Impacts, 2025.1.31.\n",
      "31) AP news, Italy blocks access to the Chinese AI application DeepSeek to protect users' data, 2025.1.31.\n",
      "32) 국정원, 「딥시크」 서비스 활용시 보안유의 강조, 2025.2.9.\n",
      "33) Global Times, Cyberattacks against DeepSeek escalate with botnets joining, command surging over 100 times: lab, 2025.1.30.\n",
      "34) Cybernews, How Deepseek's security failures shape the future of cyber defense on AI, 2025.2.10.\n",
      "35) Microsoft, Securing DeepSeek and other AI systems with Microsoft Security, 2025.2.13.\n",
      "['#/texts/204', '#/texts/205', '#/texts/206', '#/texts/207', '#/texts/208', '#/texts/209', '#/texts/210', '#/texts/211', '#/texts/212', '#/texts/213', '#/texts/214', '#/texts/215']\n",
      "==================================================\n",
      "<주요국의 딥시크 규제 및 제한 현황>\n",
      "*출처:  소프트웨어정책연구소 정리(2025.2.16.)\n",
      "36) CNBC, NASA becomes latest federal agency to block China's DeepSeek on 'security and privacy concerns', 2025.1.31.\n",
      "37) AP news, House lawmakers push to ban AI app DeepSeek from US government devices, 2025.2.6.\n",
      "38) New York Post, New York bans DeepSeek from government devices over 'serious' data privacy, censorship concerns, 2025.2.10.\n",
      "39) euronews, DeepSeek: Which countries have restricted the Chinese AI company or are questioning it?, 2025.2.3.\n",
      "40) Reuters, DeepSeek may face further regulatory actions, EU privacy watchdog says, 2025.2.12.\n",
      "41) Reuters, Australia bans DeepSeek on government devices citing security concerns, 2025.2.5.\n",
      "42) Reuters, Taiwan says government departments should not use DeepSeek, citing security concerns, 2025.1.31.\n",
      "43) Kyodo News, Toyota, other major Japanese firms ban use of China's DeepSeek, 2025.2.12.\n",
      "44) 연합뉴스, 외교·산업부, 딥시크 접속 차단…카카오 등 기업도 '금지령', 2025.2.5.\n",
      "45) 서울경제, 서울대도 딥시크 주의보…\"개인정보 안전성 확인 전까지 접속차단\", 2025.2.13.\n",
      "['#/texts/220', '#/texts/221', '#/texts/222', '#/texts/223', '#/texts/224', '#/texts/225', '#/texts/226', '#/texts/227', '#/texts/228', '#/texts/229', '#/texts/230']\n",
      "==================================================\n",
      "£ (대규모  AI  모델  학습  방법의  전환  가능성)  딥시크는  MoE  등의  혁신적인  기술을  활용하여 AI  모델  학습  방식의  변화를  촉발할  수  있음\n",
      "∙ 미래의 AI 모델들은 연산 비용을 최소화하면서도 성능을 유지할 수 있는 유사한 최적화 기법을 도입하는 사례가 증가할 전망\n",
      "∙ 딥시크가 출시되기 전에 주요 AI 모델의 비용은 지난 2년 동안 연간 기준으로 이미 약 80% 하락했으며, 딥시크는 이러한 추세를 가속화할 것으로 예상\n",
      "*  출처:  reuters.com 46)\n",
      "<주요 AI  모델의 토큰 가격(단위: 달러/백만 토큰)>\n",
      "['#/texts/237', '#/texts/238', '#/texts/241', '#/texts/239']\n",
      "==================================================\n",
      "£ (새로운  최적화  기법의  확산)  딥시크의  강화학습  기법,  특히  GRPO  기법은  향후  AI  모델 개발에 상당한 영향을 미칠 수 있음\n",
      "∙ 혁신적인 강화학습 기반 기법은 AI 모델의 학습 효율성의 향상에 기여해 이러한 방식을 도입하는 AI 기업의 증가 예상\n",
      "∙ 콜드스타트 데이터 및 지식증류 기법은 최소한의 학습 데이터로도 AI 모델을 효율적으로 운영할 수 있도록 지원하여 산업 표준에 영향을 미칠 전망\n",
      "∙ 그러나 딥시크 R1 모델이 발표된 지 1달 이내인 현시점에서는 딥시크의 최적화 기법들이 전통적인 딥러닝 모델과 비교해 장기적으로 어떤 이점을 제공할지는 추가적인 실증적 검증이 필요한 상황\n",
      "['#/texts/243', '#/texts/244', '#/texts/245']\n",
      "==================================================\n",
      "£ (AI 산업계의  혁신  촉발)  딥시크의  AI  기술  혁신은  오픈AI,  구글,  앤스로픽과  기존의 선도적인 AI 기업의 전략에 상당한 영향을 미칠 전망\n",
      "∙ 딥시크가 PTX(Portable  Thread  Execution)*를  사용하여  엔비디아의  CUDA  라이브러리를  회피하고, GPU 최적화를 극대화한 사례는 향후 기업들의 AI 모델 개발 비용을 낮추는 효과를 가져올 전망\n",
      "*  다만, 딥시크가 사용한 PTX는 엔비디아가 개발한 저수준 프로그래밍 언어라는 점에서, 여전히 엔비디아 GPU 아키텍처에 의존할 가능성이 높음\n",
      "∙ 특히, AI 산업이 대규모 범용 모델 중심에서 벗어나 특정 산업 및 목적에 최적화된 맞춤형 AI 모델 개발로 이동할 것으로 예상되며, 이러한 흐름 속에서 오픈소스 AI 모델의 활용이 더욱 증가할 전망\n",
      "['#/texts/251', '#/texts/252', '#/texts/253']\n",
      "==================================================\n",
      "£ (AI  비즈니스  모델  변화  폐쇄형  모델  vs.  개방형  모델)  딥시크의  오픈소스  전략은  오픈AI 및 구글과 같은 폐쇄형 AI 모델 전략과 직접적인 경쟁 체계를 형성 가능\n",
      "∙ 딥시크가 경쟁력 있는 성능을 더 낮은 비용으로 제공할 경우, AI 산업 전반에서 오픈소스 친화적인 비즈니스 모델로 전환하는 기업들이 증가할 것으로 예상\n",
      "∙ 그러나 보안, 규제 준수, 특수 AI 애플리케이션이 필요한 산업(금융, 의료, 국방)에서는 폐쇄형 AI 모델이 향후 강력한 시장 입지를 유지할 가능성 존재\n",
      "['#/texts/255', '#/texts/256']\n",
      "==================================================\n",
      "£ (미국과  중국  간  AI  개발  경쟁의  가속화)  딥시크의  출현은  미국과  중국  간  AI  패권  경쟁을 가속화하는 요인으로 작용 가능\n",
      "∙ 오픈AI 및 구글이 서구 시장을 주도하는 반면, 딥시크를 필두로 한 중국의 AI 기업들은 아시아 및 신흥 경제국을 중심으로 영향력을 확대할 가능성 대두\n",
      "∙ 각국 정부는 기술 주권을 확보하기 위해 AI 연구 개발에 대한 투자를 더욱 강화할 가능성이 높으며, 글로벌 AI 거버넌스 구조에도 변화가 생길 가능성 존재\n",
      "['#/texts/259', '#/texts/260']\n",
      "==================================================\n",
      "£ (중국  AI  기업의  글로벌  시장  확장  가능성)  딥시크를  비롯한  중국  AI  기업들은  규제  및 지정학적 긴장에도 불구하고 국제 시장에서 영향력을 확대할 기회를 얻게 될 전망\n",
      "∙ 동남아, 중동, 아프리카 국가들은 미국 중심의 AI 기술에 대한 대안으로 중국 AI 기술을 채택할 가능성 존재\n",
      "∙ 다만, 데이터 보안, 국제 규제 준수, 정치적 검열 문제가 서구 시장에서 중국 AI 모델 확산을 저해하는 주요 요인이 될 것으로 예상\n",
      "['#/texts/262', '#/texts/263']\n",
      "==================================================\n",
      "£ (AI  기술  혁신  및  생태계  조성)  국내에서도  AI  기술  혁신을  위해  정부  차원의  R&D  투자  확대, AI  반도체와 연산 인프라 확보, 비용 절감형 AI 개발, 오픈소스 생태계 활성화 등의 전략이 필요\n",
      "∙ 주요국들은 AI 연구개발(R&D)에 매년 대규모 자금을 투입하고 있으며, 특히, 딥시크 등장의 영향으로 오픈소스 기반의 AI 생태계를 확대할 것으로 전망\n",
      "∙ 다수의 스타트업과 연구자들이 AI 모델을 개발할 수 있도록 오픈소스 AI 모델 개발·공유 생태계 활성화 필요\n",
      "∙ 국내에서도 스타트업의 초기 개발 비용과 연산 자원(GPU 등), 경쟁력 있는 AI 인재 확보 등의 어려움을 해소할 수 있도록 정부 차원의 기금 지원 및 AI 개발 인프라 제공이 필요\n",
      "∙ 딥시크가 엔비디아의 고가 GPU를 사용하지 않고도 비용을 절감한 사례를 고려할 때, 한국도 자체적인 AI 반도체 개발 및 저비용 고효율 AI 모델 개발에 투자 필요\n",
      "['#/texts/268', '#/texts/269', '#/texts/270', '#/texts/271']\n",
      "==================================================\n",
      "£ (글로벌  AI  협력  및  시장  진출  전략  다각화)  우리나라가  글로벌  AI  시장에서  주도적인 역할을 하기 위해서는 균형 잡힌 국제협력 전략과 적극적인 해외시장 개척이 필요\n",
      "∙ 중국과 미국이 AI 패권을 두고 경쟁하는 가운데, 한국은 AI 연구 협력과 시장 확장을 균형 있게 추진할 필요\n",
      "∙ AI  선진국(미국·유럽)과  협력하여  첨단  AI  기술  연구  및  AI  거버넌스  논의에  적극  참여하면서,  신흥 시장(동남아, 중동, 아프리카) 개척을 병행하는 전략 요구\n",
      "∙ 국내 기업들의 글로벌 AI 시장에서 경쟁력 확보를 위해 정부 차원의 지원(글로벌 네트워크 구축, 규제 대응 지원 등)이 필요\n",
      "['#/texts/273', '#/texts/274', '#/texts/275']\n",
      "==================================================\n",
      "£ (AI  신뢰·안전  거버넌스  구축)  우리나라  AI  산업의  지속적인  발전을  위해서는  신뢰성과  안전성을 갖춘 AI 거버넌스 체계 구축 필요\n",
      "∙ AI 기술이 빠르게 발전하면서, AI의 투명성, 공정성, 안전성 보장과 함께, 핵심 기술을 확보하여 국가 기술 주권을 강화하는 것이 필수적인 과제가 대두\n",
      "∙ 국내 AI 신뢰성을 확보하기 위해, 알고리즘의 투명성을 강화하고, AI 학습 데이터 품질 및 개인정보 보호 체계를 더 정교하게 구축 필요\n",
      "∙ 국제 및 지역별 AI 규제 흐름을 면밀히 분석하고, 변화하는 법적 요구 사항에 기민하게 대응할 수 있도록 유연하고 체계적인 법·제도적 기반을 마련할 필요\n",
      "['#/texts/277', '#/texts/278', '#/texts/279']\n",
      "==================================================\n",
      "[참고 문헌]\n",
      "1. AP news, House lawmakers push to ban AI app DeepSeek from US government devices, 2025.2.6.\n",
      "2. AP news, Italy blocks access to the Chinese AI application D eepSeek to protect users' data, 2025.1.31.\n",
      "3. Bain  &  Company,  DeepSeek:  A  Game  Changer  in  AI  Efficiency?,  2025.2.5.\n",
      "4. bruegel,  The  geopolitics  of  artificial  intelligence  after  DeepSeek,  2025.2.4.\n",
      "5. China  Daily,  DeepSeek's  AI  breakthrough  widely  recognized  by  US  tech  industry,  2025.2.12.\n",
      "6. CIO,  How  DeepSeek  changes  the  gen  AI  equation  for  CIOs,  2025.1.30.\n",
      "7. CNBC,  NASA  becomes  latest  federal  agency  to  block  China's  DeepSeek  on  'security  and privacy  concerns',  2025.1.31.\n",
      "8. Cybernews, How Deepseek's security failures shape the future of cyber defense on AI, 2025.02.10.\n",
      "9. DeepSeek-AI,  DeepSeek-R1:  Incentivizing  Reasoning  Capability  in  LLMs  via  Reinforcement Learning,  2025.1.22.\n",
      "10. DeepSeek-AI,  DeepSeek-R1  Release,  2025.1.20.\n",
      "11. DeepSeek-AI,  DeepSeek-V2:  A  Strong,  Economical,  and  Efficient  Mixture-of-Experts  Language Model,  2024.5.7.\n",
      "12. DeepSeek-AI,  DeepSeek-V3  Technical  Report,  2024.12.27.\n",
      "13. DeepSeek-AI,  DeepSeekMath:  Pushing  the  Limits  of  Mathematical  Reasoning  in  Open  Language Models, 2024.4.24.\n",
      "14. Deloitte,  딥시크가  촉발한  새로운  AI  경쟁시대,  2025.2.\n",
      "15. DLA  PIPER,  China  releases  AI  safety  governance  framework,  2024.09.12.\n",
      "16. euronews,  DeepSeek:  Which  countries  have  restricted  the  Chinese  AI  company  or  are questioning  it?,  2025.2.3.\n",
      "17. Financial  times,  Transcript: Tech in 2025 - China's AI 'Sputnik moment', 2025.1.30.\n",
      "18. Forbes,  Why DeepSeek's New AI Model Should Prompt Reality Checks For Companies, 2025. 1.29.\n",
      "19. Geop  litical  Monitor,  The Global AI Race: The Geopolitics of DeepSeek, 2025. 2.12.\n",
      "20. Global Times, Cyberattacks against DeepSeek escalate with botnets joining, command surging over 100 times: lab, 2025.1.30.\n",
      "21. IDC,  DeepSeek's  AI  Innovation:  A  Shift  in  AI  Model  Efficiency  and  Cost  Structure,  2025.1.31.\n",
      "22. Kyodo  News,  Toyota, other major Japanese firms ban use of China's DeepSeek, 2025.2.12.\n",
      "23. HAI,  How Disruptive Is DeepSeek? Stanford HAI Faculty Discuss China's New Model, 2025.2.13.\n",
      "24. Medium, Gemini 2.0 Pro vs DeepSeek R1: The AI Showdown Y ou Didn't Know Y ou Needed, 2025.2.6.\n",
      "25. Medium, Multi-head Latent Attention (MLA): Secret behind the success of DeepSeek Large Language Models, 2025.1.31.\n",
      "26. Microsoft, Securing DeepSeek and other AI systems with Microsoft Security, 2025.2.13.\n",
      "27. neptune.ai,  Knowledge  Distillation:  Principles,  Algorithms,  Applications,  2023.09.29.\n",
      "28. New  York  Post,  New  York  bans  DeepSeek  from  government  devices  over  'serious'  data privacy,  censorship  concerns,  2025.2.10.\n",
      "29. Reuters,  Australia bans DeepSeek on government devices citing security concerns,  2025.2.5.\n",
      "30. Reuters,  Chinese chip makers, cloud providers rush to embrace homegrown DeepSeek, 2025.2.5.\n",
      "31. Reuters,  DeepSeek may face further regulatory actions, EU privacy watchdog says,  2025.2.12.\n",
      "['#/texts/283', '#/texts/284', '#/texts/285', '#/texts/286', '#/texts/287', '#/texts/288', '#/texts/289', '#/texts/290', '#/texts/291', '#/texts/292', '#/texts/293', '#/texts/294', '#/texts/295', '#/texts/296', '#/texts/297', '#/texts/298', '#/texts/299', '#/texts/300', '#/texts/301', '#/texts/302', '#/texts/303', '#/texts/304', '#/texts/305', '#/texts/306', '#/texts/307', '#/texts/308', '#/texts/309', '#/texts/310', '#/texts/311', '#/texts/312', '#/texts/313']\n",
      "==================================================\n",
      "SPRi AI Brief Special | 2025-2월호\n",
      "32. Reuters,  Four ways DeepSeek could change everything,  2025.2.12.\n",
      "33. Reuters,  French privacy watchdog to quiz DeepSeek on AI, data protection,  2025.1.31.\n",
      "34. Reuters,  South  Korean  ministries  block  DeepSeek  on  security  concerns,  officials  say,  2025.2.6.\n",
      "35. Reuters, T aiw an says go vernm ent departm ents should not use D eepS eek, citing security c oncerns, 2025.1.31.\n",
      "36. Science  Media  Centre,  expert  reaction  to  new  AI  Chatbot  DeepSeek,  2025.1.28.\n",
      "37. SemiAnalysis,  Seek  Debates:  Chinese  Leadership  On  Cost,  True  Training  Cost,  Closed Model  Margin  Impacts,  2025.1.31.\n",
      "38. The Alan Turing Institute, B rief analysis of D eepS eek R 1 and its im plication s for G enerative A I, 2025.2.7.\n",
      "39. The  Wall  Street  Journal,  Six  Takeaways  From  a  Monumental  Week  for  AI,  2025.2.2.\n",
      "40. Xinhuanet, D eepSeek gains popularity in R ussia for high-quality content, accessibility: m edia, 2025.2.12.\n",
      "41. 국정원, 「딥시크」 서비스 활용시 보안유의 강조, 2025.2.9.\n",
      "42. 서울경제, 서울대도 딥시크 주의보…\"개인정보 안전성 확인 전까지 접속차단\", 2025.2.13.\n",
      "43. 연합뉴스, 외교·산업부, 딥시크 접속 차단…카카오 등 기업도 '금지령', 2025.2.5.\n",
      "홈페이지 : https://spri.kr/ 보고서와 관련된 문의는 AI정책연구실(hs.lee@spri.kr, 031-739-7333)으로 연락주시기 바랍니다.\n",
      "['#/texts/316', '#/texts/317', '#/texts/318', '#/texts/319', '#/texts/320', '#/texts/321', '#/texts/322', '#/texts/323', '#/texts/324', '#/texts/325', '#/texts/326', '#/texts/327', '#/texts/329']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "    print(doc.page_content)\n",
    "    print([x[\"self_ref\"] for x in doc.metadata[\"dl_meta\"][\"doc_items\"]])\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f46dc",
   "metadata": {},
   "source": [
    "# 2. 벡터 DB 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d78f30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-m3\",  # 또는 multilingual: \"BAAI/bge-m3\"\n",
    "    model_kwargs={\"device\": \"mps\"},  # or \"cuda\" / \"mps\"\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")\n",
    "# normalize_embeddings=True는 FAISS에서 추천됨 (코사인 유사도 정확도 향상)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "692b06f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MacOS 환경으로 인해 pip install faiss-cpu를 설치했으나, cuda가 지원된다면 faiss-gpu를 설치하는 것을 권장\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# FAISS 벡터 DB 생성\n",
    "vectordb = FAISS.from_documents(docs, embedding_model)\n",
    "\n",
    "# 로컬 디렉토리에 저장\n",
    "vectordb.save_local(\"my-vectordb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8ff9d5",
   "metadata": {},
   "source": [
    "# 3. 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf5bcc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "£ (한계) 딥시크는  텍스트  및  수치  데이터  처리에  강점을  갖지만,  멀티모달  기능이 제한적이며, 중국의 규제로 인해 정치적으로 민감한 주제에 대한 응답을 제한 27)28)\n",
      "∙ 딥시크는 주로 텍스트 및 수치 데이터 처리에 중점을 두어 멀티모달 기능이 제한적인 반면, 구글 Gemini는 텍스트, 이미지, 오디오, 비디오 입력을 처리할 수 있는 멀티모달 기능을 갖추고 있음\n",
      "∙ 딥시크는 중국의 규제 환경에서 운영되어 정치적으로 민감한 주제에 대한 응답이 제한적이므로 표현의 자유를 중시하는 국가에서는 딥시크의 도입에 대해 부정적일 수 있음\n",
      "==================================================\n",
      "2)  기술적  강점과  한계\n",
      "£ (강점)  딥시크는  중국어  자연어  처리에서  강점을  보이며,  컴퓨팅  인프라가  제한된  기업에도 적합하고, 유연한 오픈소스 전략으로 중국 AI 생태계 내에서 널리 채택\n",
      "∙ 딥시크는 자연어 처리 작업에서 우수한 성능을 보이며, 특히 중국어 기반 작업에서 두각을 나타냄 25)\n",
      "∙ 상대적으로 낮은 하드웨어 요구사항으로 컴퓨팅 인프라가 제한적인 기업에 적합 26)\n",
      "∙ 딥시크는 유연한 오픈소스 전략으로 중국 AI 생태계 내에서 광범위한 도입 진행 중\n",
      "* BYD를  포함한  자동차  제조업체  8곳,  최소  9개의  금융증권  회사,  국유  통신  사업자  3곳이  딥시크와의  통합을  추진하고, 클라우드 컴퓨팅 사업자 알리바바, 화웨이, 텐센트, 바이두는 고객이 딥시크의 최신 모델을 이용하는 방법을 제공\n",
      "24) Bain & Company, DeepSeek: A Game Changer in AI Efficiency?, 2025.2.5.\n",
      "25) DeepSeek-AI, DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning, 2025.1.22.\n",
      "26)  Financial times, Transcript: Tech in 2025 - China's AI 'Sputnik moment', 2025.1.30.\n",
      "==================================================\n",
      "딥시크(DeepSeek)의 등장과 영향\n",
      "최근 중국의 스타트업인 딥시크는 DeepSeek-R1 모델을 출시하며 크게 주목받고 있다. 딥시크가 개발한 AI  모델은  중국  내에서는  AI  독립성을  강화하는  기술로  평가되고, 벤치마킹  결과  특정  작업에서  오픈AI의  GPT-4와  경쟁할  수  있는  성능을  보였다고 보고하지만, 국제적으로는 정책 검열, 보안, 개인정보보호 관련 우려가 제기된다. 미국, 유럽 등 여러 국가에서 데이터 보안 및 개인정보 보호 문제로 딥시크의 사용을 제한하는 조치가 확대되고 있다. 이러한 논란 속에서도 딥시크는 AI 시장의 새로운 경쟁 구도를 형성하고 있으며, 향후 글로벌 AI 산업의 변화에 중대한 영향을 미칠 것으로 전망된다.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "vectordb = FAISS.load_local(\"my-vectordb\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# 바로 search 가능\n",
    "results = vectordb.similarity_search(\"딥씨크의 기술적 한계\", k=3)\n",
    "for r in results:\n",
    "    print(r.page_content)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d599d88",
   "metadata": {},
   "source": [
    "# 4. 응답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75d707d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_openai import ChatOpenAI \n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "retriever = vectordb.as_retriever()\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=model, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f819445b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<V3  모델의  주요  기술>\n",
      "MoE (Mixture-of-Experts), 주요내용 = ∙ V3모델은MoE를적용해특정작업에적합한신경망모듈만활성화함으로써연산효율성과응답품질을최적화 ∙ 특히, 기초모델을수학,코딩등특정작업에최적화된여러개의소규모전문가모델로나누어 학습부담을줄이는방식을적용 ∙ 딥시크가MoE 기술을적용하였다는측면에서는DeepSeek-V3의 아키텍처가완전히새로운 혁신이라기보다는기존연구의발전형태로볼수있다는평가도존재. MLA(Multi-head Latent Attention), 주요내용 = ∙ 딥시크의V3모델은기존MHA(Multi-head-Attention) 대비개선된MLA기술을적용하여더욱더 효율적으로정보를처리하고,계산속도를높이면서도메모리사용량을줄여추론을빠르게수행. 보조손실(auxiliary-loss) 없는로드밸런싱, 주요내용 = ∙ 기초적인 구조를 갖는 MoE 모델에서는 일반적으로 전문가 모델 간의 부하를 균등하게 분배 하기위해추가적인손실(loss)을 설정 ∙ 보조손실없는로드밸런싱을갖는V3는추가손실없이도효과적으로부하를분산하도록설계. 다중토큰예측(Multi-token Prediction), 주요내용 = ∙ 일반적인언어모델은한번에하나의토큰을예측하지만,V3모델은한번에여러개의토큰을 예측하는방식을적용하여성능을향상\n",
      "14) DeepSeek-AI, DeepSeek-V3 Technical Report, 2024.12.27.\n",
      "15) The Alan Turing Institute, Brief analysis of DeepSeek R1 and its implications for Generative AI, 2025.2.7.\n",
      "3\n",
      "==================================================\n",
      "£ 딥시크의 V3 모델은 전문가 혼합(Mixture-of-Experts, MoE) 아키텍처 기반한 언어모델로, 딥시크 R1 모델 개발을 위한 기초 모델(Basic Model)로 사용\n",
      "∙ V3  모델은  총  6,710억  개(671B)의  파라미터를  보유하고  있지만,  각  토큰을  처리할  때  활성화되는 파라미터는 370억 개(37B)만 사용하도록 설계\n",
      "∙ 총 14.8조 개의 고품질 데이터를 사용하여 사전학습하고, 지도학습 미세조정(Supervised Fine-Tuning)과 강화학습(Reinforcement Learning, RL)을 통해 모델의 성능을 극대화\n",
      "∙ 총 2.788M(278만 8천) H800 GPU 시간을 소요하여 학습을 완료(최신 AI 모델 중에서도 비교적 저렴한 비용으로 학습)\n",
      "∙ V3 모델은 다른 오픈소스 모델보다 우수한 성능을 보이고, 폐쇄형 모델(예: OpenAI GPT-4 등)과 경쟁할 만한 성능을 기록\n",
      "==================================================\n",
      "<V3  모델  아키텍쳐>\n",
      "- *  출처:  DeepSeek-A,  DeepSeek-V3  Technical  ReportI 16)\n",
      "==================================================\n",
      "£ R1  모델은 특정 응용 분야에서 강점을 보이며, 현재 가장 발전된 AI 모델들과 경쟁 가능성 보유\n",
      "∙ 딥시크는 벤치마크 평가에서 R1 모델이 오픈AI의 o1 모델과 성능이 동등하거나 높으며, 비용은 o1 모델 대비 저렴하고, R1 모델의 기반이 된 V3 모델 학습 시 엔비디아 H100보다 성능이 절반 수준인 H800 2천 개를 사용하고, 학습 비용이 약 560만 달러에 불과했다고 주장 21)\n",
      "*  수학  관련  AIME  2024와  MATH-500  벤치마크에서  R1  모델은  각각  79.8%와  97.3%의  정확도로  o1  모델의  79.2%과 96.4%를 능가했으며, 기타 벤치마크에서도 o1 모델과 근소한 차이를 기록\n",
      "∙ 한편, 미국 기술 산업계 일부는 딥시크가 주장한 560만 달러는 전체 개발비의 일부일 뿐이며 H800 외에 고사양 GPU를 혼합하여 학습했을 수도 있다고 추측도 있음 22)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "question = \"V3 모델의 주요 기술이 뭐야?\"\n",
    "results = retriever.invoke(question)\n",
    "for r in results:\n",
    "    print(r.page_content)\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7be8cfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: V3 모델의 주요 기술은 다음과 같습니다:\n",
      "\n",
      "1. **Mixture-of-Experts (MoE)**: V3 모델은 특정 작업에 적합한 신경망 모듈만 활성화하여 연산 효율성과 응답 품질을 최적화합니다. 여러 개의 소규모 전문가 모델로 나누어 학습 부담을 줄이는 방식입니다.\n",
      "\n",
      "2. **Multi-head Latent Attention (MLA)**: 기존의 Multi-head Attention (MHA) 대비 개선된 기술로, 정보 처리의 효율성을 높이고 계산 속도를 향상시키며 메모리 사용량을 줄입니다.\n",
      "\n",
      "3. **보조손실 없는 로드밸런싱**: V3는 추가 손실 없이도 효과적으로 부하를 분산하도록 설계되었습니다.\n",
      "\n",
      "4. **다중토큰 예측**: 일반적인 언어 모델이 한 번에 하나의 토큰을 예측하는 것과 달리, V3 모델은 한 번에 여러 개의 토큰을 예측하는 방식을 적용하여 성능을 향상시킵니다.\n"
     ]
    }
   ],
   "source": [
    "# 4. 사용자 질문 응답\n",
    "question = \"V3 모델의 주요 기술이 뭐야?\"\n",
    "response = qa_chain.invoke(question)\n",
    "print(\"답변:\", response[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
